{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8cb3db",
   "metadata": {},
   "source": [
    "# Multimodal Training Notebook (Audio + Video + Fusion)\n",
    "\n",
    "This notebook runs a high-accuracy workflow with **video multiclass tuning first**:\n",
    "1. Configure shared settings\n",
    "2. Run video multiclass research sweep\n",
    "3. Train/evaluate final video model with best config\n",
    "4. Train/evaluate fusion model using trained audio + video checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15aae16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python      : /home/alolli/miniconda3/envs/therness_env/bin/python\n",
      "Project root: /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito\n",
      "Config path : /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Setup\n",
    "import json, os, sys, shlex, subprocess, select, pty\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "PYTHON = sys.executable\n",
    "CONFIG_PATH = PROJECT_ROOT / 'configs' / 'master_config.json'\n",
    "\n",
    "def _stream(cmd, cwd=None):\n",
    "    cmd = [str(c) for c in cmd]\n",
    "    print('$', ' '.join(shlex.quote(c) for c in cmd), flush=True)\n",
    "    env = {**os.environ, 'PYTHONUNBUFFERED': '1'}\n",
    "\n",
    "    master, slave = pty.openpty()\n",
    "    p = subprocess.Popen(\n",
    "        cmd, cwd=str(cwd or PROJECT_ROOT), env=env,\n",
    "        stdin=slave, stdout=slave, stderr=slave, close_fds=True,\n",
    "    )\n",
    "    os.close(slave)\n",
    "\n",
    "    while p.poll() is None:\n",
    "        r, _, _ = select.select([master], [], [], 0.05)\n",
    "        if r:\n",
    "            try:\n",
    "                data = os.read(master, 4096)\n",
    "            except OSError as e:\n",
    "                # PTY often raises EIO when child has exited; treat as EOF\n",
    "                if getattr(e, 'errno', None) == 5:\n",
    "                    break\n",
    "                raise\n",
    "            if not data:\n",
    "                break\n",
    "            sys.stdout.write(data.decode('utf-8', errors='replace'))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            r, _, _ = select.select([master], [], [], 0.1)\n",
    "            if not r:\n",
    "                break\n",
    "            try:\n",
    "                data = os.read(master, 4096)\n",
    "            except OSError as e:\n",
    "                if getattr(e, 'errno', None) == 5:\n",
    "                    break\n",
    "                raise\n",
    "            if not data:\n",
    "                break\n",
    "            sys.stdout.write(data.decode('utf-8', errors='replace'))\n",
    "            sys.stdout.flush()\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.close(master)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    rc = p.wait()\n",
    "    print(f'\\n[exit {rc}]', flush=True)\n",
    "    if rc != 0:\n",
    "        raise subprocess.CalledProcessError(rc, cmd)\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    CFG = json.load(f)\n",
    "\n",
    "print(f'Python      : {PYTHON}')\n",
    "print(f'Project root: {PROJECT_ROOT}')\n",
    "print(f'Config path : {CONFIG_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95658c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config updated.\n",
      "  video epochs      : 70\n",
      "  video num_frames  : 12\n",
      "  video clip_seconds: None\n",
      "  video img_size    : 160\n",
      "  video dropout     : 0.12\n",
      "  video lr          : 0.0001\n",
      "  video wd          : 7e-05\n",
      "  fusion epochs     : 90\n",
      "  audio ckpt: checkpoints/audio_multiclass/best_model.pt\n",
      "  video ckpt: checkpoints/video/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — High-accuracy multimodal config\n",
    "# Edit only if needed, then run this cell once before training.\n",
    "\n",
    "DATA_ROOT = '/data1/malto/therness/data/Hackathon'\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "AUDIO_CKPT = 'checkpoints/audio_multiclass/best_model.pt'\n",
    "VIDEO_CKPT = 'checkpoints/video/best_model.pt'\n",
    "FUSION_CKPT = 'checkpoints/fusion/best_model.pt'\n",
    "\n",
    "# Video training — loads pre-extracted JPEGs (run video/extract_frames.py once)\n",
    "CFG.setdefault('video_window', {})\n",
    "CFG['video_window'].setdefault('model', {})\n",
    "CFG['video_window'].setdefault('training', {})\n",
    "CFG['video_window']['model'].update({\n",
    "    'pretrained': True,\n",
    "    'dropout': 0.12,   # best region from latest research\n",
    "})\n",
    "CFG['video_window']['training'].update({\n",
    "    'epochs': 70,\n",
    "    'batch_size': 32,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 7e-05,\n",
    "    'num_frames': 12,\n",
    "    'clip_seconds': None,\n",
    "    'img_size': 160,\n",
    "    'frames_dir': 'data/video_frames',\n",
    "    'seed': 42,\n",
    "    'num_workers': 4,\n",
    "    'metric': 'hackathon_combined',\n",
    "    'class_weights': 'inverse_frequency',\n",
    "    'class_weight_power': 1.0,\n",
    "    'use_balanced_sampler': True,\n",
    "    'balanced_sampler_power': 0.35,\n",
    "    'split_strategy': 'group_shuffle',\n",
    "    'patience': 20,\n",
    "    'checkpoint_dir': 'checkpoints/video',\n",
    "    'lr_schedule': {\n",
    "        'warmup_ratio': 0.1,\n",
    "        'plateau_factor': 0.5,\n",
    "        'plateau_patience': 4,\n",
    "        'plateau_threshold': 1e-3,\n",
    "        'plateau_min_lr': 1e-6,\n",
    "    },\n",
    "})\n",
    "\n",
    "# Fusion training (frozen backbones + fusion head)\n",
    "CFG.setdefault('fusion', {})\n",
    "CFG['fusion'].setdefault('model', {})\n",
    "CFG['fusion'].setdefault('training', {})\n",
    "CFG['fusion']['model'].update({\n",
    "    'arch': 'temporal',\n",
    "    'audio_dim': 128,\n",
    "    'video_dim': 128,\n",
    "    'hidden_dim': 192,\n",
    "    'dropout': 0.2,\n",
    "    'temporal_layers': 1,\n",
    "})\n",
    "CFG['fusion']['training'].update({\n",
    "    'num_epochs': 90,\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 64,\n",
    "    'sequence_len': 12,\n",
    "    'val_split': 0.2,\n",
    "    'seed': 42,\n",
    "    'patience': 22,\n",
    "    'checkpoint_dir': 'checkpoints/fusion',\n",
    "})\n",
    "\n",
    "CFG['data_root'] = DATA_ROOT\n",
    "CFG['num_classes'] = NUM_CLASSES\n",
    "CFG['device'] = 'auto'\n",
    "\n",
    "with open(CONFIG_PATH, 'w') as f:\n",
    "    json.dump(CFG, f, indent=2)\n",
    "\n",
    "print('Config updated.')\n",
    "print(f'  video epochs      : {CFG[\"video_window\"][\"training\"][\"epochs\"]}')\n",
    "print(f'  video num_frames  : {CFG[\"video_window\"][\"training\"][\"num_frames\"]}')\n",
    "print(f'  video clip_seconds: {CFG[\"video_window\"][\"training\"][\"clip_seconds\"]}')\n",
    "print(f'  video img_size    : {CFG[\"video_window\"][\"training\"][\"img_size\"]}')\n",
    "print(f'  video dropout     : {CFG[\"video_window\"][\"model\"][\"dropout\"]}')\n",
    "print(f'  video lr          : {CFG[\"video_window\"][\"training\"][\"lr\"]}')\n",
    "print(f'  video wd          : {CFG[\"video_window\"][\"training\"][\"weight_decay\"]}')\n",
    "print(f'  fusion arch       : {CFG[\"fusion\"][\"model\"][\"arch\"]}')\n",
    "print(f'  fusion seq len    : {CFG[\"fusion\"][\"training\"][\"sequence_len\"]}')\n",
    "print(f'  fusion epochs     : {CFG[\"fusion\"][\"training\"][\"num_epochs\"]}')\n",
    "print(f'  audio ckpt: {AUDIO_CKPT}')\n",
    "print(f'  video ckpt: {VIDEO_CKPT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Resolve checkpoint paths (fallback to best video research ckpt)\n",
    "import glob\n",
    "\n",
    "if not (PROJECT_ROOT / AUDIO_CKPT).exists():\n",
    "    raise FileNotFoundError(f'Audio checkpoint not found: {(PROJECT_ROOT / AUDIO_CKPT).resolve()}')\n",
    "\n",
    "if not (PROJECT_ROOT / VIDEO_CKPT).exists():\n",
    "    best_video_ckpt = None\n",
    "    best_tuple = None\n",
    "    for d in glob.glob(str(PROJECT_ROOT / 'checkpoints' / 'video_research_*')):\n",
    "        m_path = Path(d) / 'best_metrics.json'\n",
    "        p_path = Path(d) / 'best_model.pt'\n",
    "        if not (m_path.exists() and p_path.exists()):\n",
    "            continue\n",
    "        with open(m_path) as f:\n",
    "            m = json.load(f)\n",
    "        macro_f1 = float(m.get('val_f1', -1.0))\n",
    "        score = float(m.get('hackathon_score', -1.0))\n",
    "        row = (macro_f1, score, str(p_path.relative_to(PROJECT_ROOT)))\n",
    "        if best_tuple is None or row > best_tuple:\n",
    "            best_tuple = row\n",
    "            best_video_ckpt = row[2]\n",
    "\n",
    "    if best_video_ckpt is None:\n",
    "        raise FileNotFoundError(\n",
    "            f'Video checkpoint not found at {(PROJECT_ROOT / VIDEO_CKPT).resolve()} and no video_research fallback available.'\n",
    "        )\n",
    "\n",
    "    VIDEO_CKPT = best_video_ckpt\n",
    "    print('VIDEO_CKPT fallback selected from research checkpoints:')\n",
    "    print(f'  {VIDEO_CKPT} (macroF1={best_tuple[0]:.4f}, score={best_tuple[1]:.4f})')\n",
    "else:\n",
    "    print(f'VIDEO_CKPT found: {(PROJECT_ROOT / VIDEO_CKPT).resolve()}')\n",
    "\n",
    "print(f'Active AUDIO_CKPT: {(PROJECT_ROOT / AUDIO_CKPT).resolve()}')\n",
    "print(f'Active VIDEO_CKPT: {(PROJECT_ROOT / VIDEO_CKPT).resolve()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d1c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed old frame cache: /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/data/video_frames\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.extract_frames --data_root /data1/malto/therness/data/Hackathon --out_dir /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/data/video_frames --num_frames 12 --img_size 160 --workers 16 --overwrite\n",
      "Scanning videos in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "Extracting: 100% 1551/1551 [01:11<00:00, 21.71it/s]\n",
      "\n",
      "Done: 1551 ok, 0 failed\n",
      "Frames saved to: /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/data/video_frames\n",
      "Manifest written to: /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/data/video_frames/manifest.json\n",
      "\n",
      "[exit 0]\n",
      "Frame extraction complete and validated.\n",
      "  frames_dir : /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/data/video_frames\n",
      "  entries    : 1551\n",
      "  num_frames : 12\n",
      "  img_size   : 160\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — Rebuild video frame cache to match training config\n",
    "import shutil\n",
    "\n",
    "RUN_FRAME_EXTRACTION = True\n",
    "FORCE_CLEAN_FRAME_CACHE = True  # True = remove old JPEG cache before extraction\n",
    "FRAME_EXTRACT_WORKERS = 16\n",
    "\n",
    "if RUN_FRAME_EXTRACTION:\n",
    "    with open(CONFIG_PATH) as f:\n",
    "        cfg_live = json.load(f)\n",
    "\n",
    "    vw_train = cfg_live.get('video_window', {}).get('training', {})\n",
    "    frames_dir = vw_train.get('frames_dir', 'data/video_frames')\n",
    "    num_frames = int(vw_train.get('num_frames', 8))\n",
    "    img_size = int(vw_train.get('img_size', 160))\n",
    "\n",
    "    if FORCE_CLEAN_FRAME_CACHE and (PROJECT_ROOT / frames_dir).exists():\n",
    "        shutil.rmtree(PROJECT_ROOT / frames_dir)\n",
    "        print(f'Removed old frame cache: {(PROJECT_ROOT / frames_dir).resolve()}')\n",
    "\n",
    "    cmd = [\n",
    "        PYTHON, '-u', '-m', 'video.extract_frames',\n",
    "        '--data_root', cfg_live['data_root'],\n",
    "        '--out_dir', str(PROJECT_ROOT / frames_dir),\n",
    "        '--num_frames', str(num_frames),\n",
    "        '--img_size', str(img_size),\n",
    "        '--workers', str(FRAME_EXTRACT_WORKERS),\n",
    "        '--overwrite',\n",
    "    ]\n",
    "    _stream(cmd)\n",
    "\n",
    "    manifest_path = PROJECT_ROOT / frames_dir / 'manifest.json'\n",
    "    if not manifest_path.exists():\n",
    "        raise FileNotFoundError(f'Manifest missing after extraction: {manifest_path}')\n",
    "\n",
    "    with open(manifest_path) as f:\n",
    "        manifest = json.load(f)\n",
    "\n",
    "    m_num_frames = int(manifest.get('num_frames', -1))\n",
    "    n_entries = len(manifest.get('entries', []))\n",
    "    if m_num_frames != num_frames:\n",
    "        raise RuntimeError(\n",
    "            f'Manifest num_frames mismatch: expected {num_frames}, got {m_num_frames}'\n",
    "        )\n",
    "\n",
    "    print('Frame extraction complete and validated.')\n",
    "    print(f'  frames_dir : {(PROJECT_ROOT / frames_dir).resolve()}')\n",
    "    print(f'  entries    : {n_entries}')\n",
    "    print(f'  num_frames : {m_num_frames}')\n",
    "    print(f'  img_size   : {manifest.get(\"img_size\", \"?\")}')\n",
    "else:\n",
    "    print('RUN_FRAME_EXTRACTION=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a533b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame cache check: OK — cache already matches config\n",
      "Video research: 12 trials × 20 epochs\n",
      "FAST_MODE=True | RESUME_RESEARCH=False | OBJECTIVE=macro_f1 | TARGET_SCORE=0.90 | RUN_VIDEO_FINAL_AFTER_RESEARCH=False\n",
      "\n",
      "[01/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9692 | Train F1: 0.0278 | Val loss: 2.0081 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9035 | Train F1: 0.0381 | Val loss: 1.9839 | Val Macro F1: 0.1447 | Val Binary F1: 0.7906 | Hackathon: 0.5323 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5323)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8537 | Train F1: 0.0943 | Val loss: 1.9043 | Val Macro F1: 0.1136 | Val Binary F1: 0.7906 | Hackathon: 0.5198 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8029 | Train F1: 0.1258 | Val loss: 1.8203 | Val Macro F1: 0.1230 | Val Binary F1: 0.7906 | Hackathon: 0.5236 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7250 | Train F1: 0.1618 | Val loss: 1.7761 | Val Macro F1: 0.2352 | Val Binary F1: 0.7906 | Hackathon: 0.5684 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5684)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6749 | Train F1: 0.1785 | Val loss: 1.6683 | Val Macro F1: 0.2397 | Val Binary F1: 0.7906 | Hackathon: 0.5702 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5702)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6036 | Train F1: 0.1943 | Val loss: 1.6436 | Val Macro F1: 0.2453 | Val Binary F1: 0.7906 | Hackathon: 0.5725 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5725)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6143 | Train F1: 0.2192 | Val loss: 1.6524 | Val Macro F1: 0.2527 | Val Binary F1: 0.7906 | Hackathon: 0.5754 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5754)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5973 | Train F1: 0.2681 | Val loss: 1.6464 | Val Macro F1: 0.3214 | Val Binary F1: 0.7906 | Hackathon: 0.6029 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6029)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5415 | Train F1: 0.2443 | Val loss: 1.6005 | Val Macro F1: 0.4231 | Val Binary F1: 0.7906 | Hackathon: 0.6436 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6436)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4846 | Train F1: 0.2949 | Val loss: 1.5504 | Val Macro F1: 0.4186 | Val Binary F1: 0.7906 | Hackathon: 0.6418 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5016 | Train F1: 0.3324 | Val loss: 1.5679 | Val Macro F1: 0.3300 | Val Binary F1: 0.7906 | Hackathon: 0.6064 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4385 | Train F1: 0.3906 | Val loss: 1.5257 | Val Macro F1: 0.4233 | Val Binary F1: 0.7906 | Hackathon: 0.6437 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6437)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4261 | Train F1: 0.3930 | Val loss: 1.4764 | Val Macro F1: 0.4004 | Val Binary F1: 0.7906 | Hackathon: 0.6345 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3867 | Train F1: 0.4079 | Val loss: 1.4948 | Val Macro F1: 0.5001 | Val Binary F1: 0.7906 | Hackathon: 0.6744 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6744)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3734 | Train F1: 0.4171 | Val loss: 1.5417 | Val Macro F1: 0.5046 | Val Binary F1: 0.7696 | Hackathon: 0.6636 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3655 | Train F1: 0.4240 | Val loss: 1.6192 | Val Macro F1: 0.4024 | Val Binary F1: 0.7906 | Hackathon: 0.6353 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3521 | Train F1: 0.4342 | Val loss: 1.5975 | Val Macro F1: 0.5277 | Val Binary F1: 0.7906 | Hackathon: 0.6854 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6854)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3966 | Train F1: 0.4143 | Val loss: 1.5704 | Val Macro F1: 0.5999 | Val Binary F1: 0.7906 | Hackathon: 0.7143 | LR: 0.0001\n",
      "New best model (hackathon_score=0.7143)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2935 | Train F1: 0.4971 | Val loss: 1.4882 | Val Macro F1: 0.3223 | Val Binary F1: 0.7906 | Hackathon: 0.6033 | LR: 5e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Training complete. Best epoch: 19 (score=0.7143)\n",
      "\n",
      "[exit 0]\n",
      "[02/12] {'lr': 0.00012, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.00012_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.00012_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.00012_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9681 | Train F1: 0.0278 | Val loss: 2.0028 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 6e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8961 | Train F1: 0.0406 | Val loss: 1.9651 | Val Macro F1: 0.1260 | Val Binary F1: 0.7906 | Hackathon: 0.5247 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5247)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8335 | Train F1: 0.1014 | Val loss: 1.8763 | Val Macro F1: 0.1112 | Val Binary F1: 0.7906 | Hackathon: 0.5188 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7716 | Train F1: 0.1450 | Val loss: 1.7821 | Val Macro F1: 0.3015 | Val Binary F1: 0.7906 | Hackathon: 0.5949 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5949)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6940 | Train F1: 0.1857 | Val loss: 1.7453 | Val Macro F1: 0.2331 | Val Binary F1: 0.7906 | Hackathon: 0.5676 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6435 | Train F1: 0.1882 | Val loss: 1.6492 | Val Macro F1: 0.2496 | Val Binary F1: 0.7906 | Hackathon: 0.5742 | LR: 0.00012\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5767 | Train F1: 0.2172 | Val loss: 1.6426 | Val Macro F1: 0.2536 | Val Binary F1: 0.7906 | Hackathon: 0.5758 | LR: 0.00012\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5846 | Train F1: 0.2462 | Val loss: 1.6287 | Val Macro F1: 0.3044 | Val Binary F1: 0.7906 | Hackathon: 0.5961 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5961)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5538 | Train F1: 0.3165 | Val loss: 1.6155 | Val Macro F1: 0.4359 | Val Binary F1: 0.7749 | Hackathon: 0.6393 | LR: 0.00012\n",
      "New best model (hackathon_score=0.6393)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4862 | Train F1: 0.3075 | Val loss: 1.5694 | Val Macro F1: 0.3956 | Val Binary F1: 0.7906 | Hackathon: 0.6326 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4481 | Train F1: 0.3703 | Val loss: 1.5363 | Val Macro F1: 0.5252 | Val Binary F1: 0.7906 | Hackathon: 0.6844 | LR: 0.00012\n",
      "New best model (hackathon_score=0.6844)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4805 | Train F1: 0.3653 | Val loss: 1.6355 | Val Macro F1: 0.5131 | Val Binary F1: 0.7775 | Hackathon: 0.6717 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4432 | Train F1: 0.4149 | Val loss: 1.4739 | Val Macro F1: 0.5090 | Val Binary F1: 0.7906 | Hackathon: 0.6779 | LR: 0.00012\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3959 | Train F1: 0.4271 | Val loss: 1.7312 | Val Macro F1: 0.2557 | Val Binary F1: 0.7906 | Hackathon: 0.5766 | LR: 0.00012\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3121 | Train F1: 0.4157 | Val loss: 1.4975 | Val Macro F1: 0.2871 | Val Binary F1: 0.7906 | Hackathon: 0.5892 | LR: 0.00012\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2736 | Train F1: 0.4528 | Val loss: 1.5501 | Val Macro F1: 0.3507 | Val Binary F1: 0.7940 | Hackathon: 0.6167 | LR: 0.00012\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2561 | Train F1: 0.4523 | Val loss: 1.6328 | Val Macro F1: 0.4201 | Val Binary F1: 0.7906 | Hackathon: 0.6424 | LR: 0.00012\n",
      "No improvement for 6 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2484 | Train F1: 0.4499 | Val loss: 1.5062 | Val Macro F1: 0.2857 | Val Binary F1: 0.7906 | Hackathon: 0.5886 | LR: 0.00012\n",
      "No improvement for 7 epoch(s)\n",
      "\n",
      "Early stopping at epoch 18\n",
      "\n",
      "Training complete. Best epoch: 11 (score=0.6844)\n",
      "\n",
      "[exit 0]\n",
      "[03/12] {'lr': 8e-05, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=8e-05_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=8e-05_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=8e-05_wd=7e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9704 | Train F1: 0.0277 | Val loss: 2.0134 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 4e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9110 | Train F1: 0.0354 | Val loss: 2.0043 | Val Macro F1: 0.1326 | Val Binary F1: 0.7906 | Hackathon: 0.5274 | LR: 8e-05\n",
      "New best model (hackathon_score=0.5274)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8745 | Train F1: 0.0839 | Val loss: 1.9355 | Val Macro F1: 0.1266 | Val Binary F1: 0.7906 | Hackathon: 0.5250 | LR: 8e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8365 | Train F1: 0.1081 | Val loss: 1.8639 | Val Macro F1: 0.1114 | Val Binary F1: 0.7906 | Hackathon: 0.5189 | LR: 8e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7648 | Train F1: 0.1527 | Val loss: 1.8211 | Val Macro F1: 0.2378 | Val Binary F1: 0.7906 | Hackathon: 0.5695 | LR: 8e-05\n",
      "New best model (hackathon_score=0.5695)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7179 | Train F1: 0.1516 | Val loss: 1.7291 | Val Macro F1: 0.2543 | Val Binary F1: 0.7906 | Hackathon: 0.5761 | LR: 8e-05\n",
      "New best model (hackathon_score=0.5761)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6427 | Train F1: 0.1672 | Val loss: 1.6723 | Val Macro F1: 0.2582 | Val Binary F1: 0.7906 | Hackathon: 0.5776 | LR: 8e-05\n",
      "New best model (hackathon_score=0.5776)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6496 | Train F1: 0.1955 | Val loss: 1.6635 | Val Macro F1: 0.2561 | Val Binary F1: 0.7906 | Hackathon: 0.5768 | LR: 8e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6264 | Train F1: 0.2549 | Val loss: 1.6548 | Val Macro F1: 0.2606 | Val Binary F1: 0.7906 | Hackathon: 0.5786 | LR: 8e-05\n",
      "New best model (hackathon_score=0.5786)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5887 | Train F1: 0.2090 | Val loss: 1.6207 | Val Macro F1: 0.3347 | Val Binary F1: 0.7906 | Hackathon: 0.6082 | LR: 8e-05\n",
      "New best model (hackathon_score=0.6082)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5493 | Train F1: 0.2311 | Val loss: 1.6192 | Val Macro F1: 0.2775 | Val Binary F1: 0.7906 | Hackathon: 0.5854 | LR: 8e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5546 | Train F1: 0.2581 | Val loss: 1.6151 | Val Macro F1: 0.3093 | Val Binary F1: 0.7906 | Hackathon: 0.5981 | LR: 8e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5158 | Train F1: 0.3076 | Val loss: 1.5851 | Val Macro F1: 0.4679 | Val Binary F1: 0.7906 | Hackathon: 0.6615 | LR: 8e-05\n",
      "New best model (hackathon_score=0.6615)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5039 | Train F1: 0.3298 | Val loss: 1.5478 | Val Macro F1: 0.2787 | Val Binary F1: 0.7906 | Hackathon: 0.5859 | LR: 8e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4697 | Train F1: 0.3582 | Val loss: 1.6844 | Val Macro F1: 0.3131 | Val Binary F1: 0.7965 | Hackathon: 0.6032 | LR: 8e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4184 | Train F1: 0.4163 | Val loss: 1.4872 | Val Macro F1: 0.4124 | Val Binary F1: 0.7906 | Hackathon: 0.6393 | LR: 8e-05\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3958 | Train F1: 0.4045 | Val loss: 1.5847 | Val Macro F1: 0.1959 | Val Binary F1: 0.7906 | Hackathon: 0.5527 | LR: 8e-05\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3395 | Train F1: 0.4293 | Val loss: 1.6111 | Val Macro F1: 0.4377 | Val Binary F1: 0.7906 | Hackathon: 0.6494 | LR: 8e-05\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3836 | Train F1: 0.4377 | Val loss: 1.5439 | Val Macro F1: 0.2164 | Val Binary F1: 0.7906 | Hackathon: 0.5609 | LR: 8e-05\n",
      "No improvement for 6 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3648 | Train F1: 0.4616 | Val loss: 1.4487 | Val Macro F1: 0.4045 | Val Binary F1: 0.7906 | Hackathon: 0.6362 | LR: 8e-05\n",
      "No improvement for 7 epoch(s)\n",
      "\n",
      "Early stopping at epoch 20\n",
      "\n",
      "Training complete. Best epoch: 13 (score=0.6615)\n",
      "\n",
      "[exit 0]\n",
      "[04/12] {'lr': 0.0001, 'weight_decay': 5e-05, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=5e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=5e-05_do=0.12_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=5e-05_do=0.12_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9674 | Train F1: 0.0278 | Val loss: 2.0033 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8913 | Train F1: 0.0480 | Val loss: 1.9642 | Val Macro F1: 0.1247 | Val Binary F1: 0.7906 | Hackathon: 0.5242 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5242)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8235 | Train F1: 0.1074 | Val loss: 1.8640 | Val Macro F1: 0.1110 | Val Binary F1: 0.7906 | Hackathon: 0.5188 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7576 | Train F1: 0.1518 | Val loss: 1.7565 | Val Macro F1: 0.3012 | Val Binary F1: 0.7906 | Hackathon: 0.5948 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5948)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6751 | Train F1: 0.1927 | Val loss: 1.7161 | Val Macro F1: 0.2324 | Val Binary F1: 0.7906 | Hackathon: 0.5673 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6217 | Train F1: 0.2016 | Val loss: 1.6117 | Val Macro F1: 0.2422 | Val Binary F1: 0.7906 | Hackathon: 0.5712 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5538 | Train F1: 0.2441 | Val loss: 1.6038 | Val Macro F1: 0.2457 | Val Binary F1: 0.7906 | Hackathon: 0.5727 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5571 | Train F1: 0.2825 | Val loss: 1.5923 | Val Macro F1: 0.4265 | Val Binary F1: 0.7906 | Hackathon: 0.6449 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6449)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5255 | Train F1: 0.3388 | Val loss: 1.5779 | Val Macro F1: 0.4967 | Val Binary F1: 0.7906 | Hackathon: 0.6730 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6730)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4510 | Train F1: 0.3348 | Val loss: 1.5362 | Val Macro F1: 0.4779 | Val Binary F1: 0.7906 | Hackathon: 0.6655 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4038 | Train F1: 0.3966 | Val loss: 1.4810 | Val Macro F1: 0.4433 | Val Binary F1: 0.7906 | Hackathon: 0.6517 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4150 | Train F1: 0.3895 | Val loss: 1.5684 | Val Macro F1: 0.4367 | Val Binary F1: 0.7906 | Hackathon: 0.6491 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3455 | Train F1: 0.4389 | Val loss: 1.5766 | Val Macro F1: 0.1077 | Val Binary F1: 0.7906 | Hackathon: 0.5174 | LR: 0.0001\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3507 | Train F1: 0.4334 | Val loss: 1.5247 | Val Macro F1: 0.4027 | Val Binary F1: 0.7906 | Hackathon: 0.6355 | LR: 0.0001\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3018 | Train F1: 0.4299 | Val loss: 1.4859 | Val Macro F1: 0.5609 | Val Binary F1: 0.7906 | Hackathon: 0.6987 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6987)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2792 | Train F1: 0.4461 | Val loss: 1.5046 | Val Macro F1: 0.3872 | Val Binary F1: 0.7906 | Hackathon: 0.6293 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2493 | Train F1: 0.4652 | Val loss: 1.4935 | Val Macro F1: 0.3667 | Val Binary F1: 0.7906 | Hackathon: 0.6211 | LR: 5e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.1750 | Train F1: 0.4999 | Val loss: 1.3848 | Val Macro F1: 0.6005 | Val Binary F1: 0.7906 | Hackathon: 0.7145 | LR: 5e-05\n",
      "New best model (hackathon_score=0.7145)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.1667 | Train F1: 0.5416 | Val loss: 1.3926 | Val Macro F1: 0.6192 | Val Binary F1: 0.7906 | Hackathon: 0.7220 | LR: 5e-05\n",
      "New best model (hackathon_score=0.7220)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.1293 | Train F1: 0.5707 | Val loss: 1.3726 | Val Macro F1: 0.6855 | Val Binary F1: 0.7906 | Hackathon: 0.7485 | LR: 5e-05\n",
      "New best model (hackathon_score=0.7485)\n",
      "\n",
      "Training complete. Best epoch: 20 (score=0.7485)\n",
      "\n",
      "[exit 0]\n",
      "[05/12] {'lr': 0.0001, 'weight_decay': 0.0001, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=0.0001_do=0.12_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=0.0001_do=0.12_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=0.0001_do=0.12_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9707 | Train F1: 0.0277 | Val loss: 2.0117 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9133 | Train F1: 0.0322 | Val loss: 1.9992 | Val Macro F1: 0.1356 | Val Binary F1: 0.7906 | Hackathon: 0.5286 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5286)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8794 | Train F1: 0.0846 | Val loss: 1.9362 | Val Macro F1: 0.1260 | Val Binary F1: 0.7906 | Hackathon: 0.5247 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8435 | Train F1: 0.1071 | Val loss: 1.8711 | Val Macro F1: 0.1110 | Val Binary F1: 0.7906 | Hackathon: 0.5188 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7739 | Train F1: 0.1433 | Val loss: 1.8331 | Val Macro F1: 0.2384 | Val Binary F1: 0.7906 | Hackathon: 0.5697 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5697)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7307 | Train F1: 0.1446 | Val loss: 1.7454 | Val Macro F1: 0.2499 | Val Binary F1: 0.7906 | Hackathon: 0.5743 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5743)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6571 | Train F1: 0.1557 | Val loss: 1.6968 | Val Macro F1: 0.2586 | Val Binary F1: 0.7906 | Hackathon: 0.5778 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5778)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6645 | Train F1: 0.1843 | Val loss: 1.6897 | Val Macro F1: 0.2498 | Val Binary F1: 0.7906 | Hackathon: 0.5743 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6469 | Train F1: 0.2368 | Val loss: 1.6912 | Val Macro F1: 0.2366 | Val Binary F1: 0.7906 | Hackathon: 0.5690 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6066 | Train F1: 0.1872 | Val loss: 1.6651 | Val Macro F1: 0.3543 | Val Binary F1: 0.7906 | Hackathon: 0.6161 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6161)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5653 | Train F1: 0.2208 | Val loss: 1.6515 | Val Macro F1: 0.2569 | Val Binary F1: 0.7906 | Hackathon: 0.5771 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5689 | Train F1: 0.2644 | Val loss: 1.6386 | Val Macro F1: 0.2842 | Val Binary F1: 0.7906 | Hackathon: 0.5880 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5097 | Train F1: 0.3557 | Val loss: 1.6237 | Val Macro F1: 0.3310 | Val Binary F1: 0.7906 | Hackathon: 0.6068 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4901 | Train F1: 0.3797 | Val loss: 1.6117 | Val Macro F1: 0.4014 | Val Binary F1: 0.7906 | Hackathon: 0.6349 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6349)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4533 | Train F1: 0.3918 | Val loss: 1.5542 | Val Macro F1: 0.4171 | Val Binary F1: 0.7906 | Hackathon: 0.6412 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6412)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4472 | Train F1: 0.4036 | Val loss: 1.5759 | Val Macro F1: 0.4231 | Val Binary F1: 0.7906 | Hackathon: 0.6436 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6436)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4403 | Train F1: 0.4001 | Val loss: 1.5673 | Val Macro F1: 0.4806 | Val Binary F1: 0.7906 | Hackathon: 0.6666 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6666)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3699 | Train F1: 0.4244 | Val loss: 1.4710 | Val Macro F1: 0.4105 | Val Binary F1: 0.7906 | Hackathon: 0.6385 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3928 | Train F1: 0.4598 | Val loss: 1.5109 | Val Macro F1: 0.4105 | Val Binary F1: 0.7906 | Hackathon: 0.6386 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3673 | Train F1: 0.4649 | Val loss: 1.5682 | Val Macro F1: 0.3148 | Val Binary F1: 0.7906 | Hackathon: 0.6003 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Training complete. Best epoch: 17 (score=0.6666)\n",
      "\n",
      "[exit 0]\n",
      "[06/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.1, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.1_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.1_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.1_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9669 | Train F1: 0.0283 | Val loss: 2.0078 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9016 | Train F1: 0.0378 | Val loss: 1.9833 | Val Macro F1: 0.1447 | Val Binary F1: 0.7906 | Hackathon: 0.5323 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5323)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8505 | Train F1: 0.0916 | Val loss: 1.9036 | Val Macro F1: 0.1136 | Val Binary F1: 0.7906 | Hackathon: 0.5198 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7971 | Train F1: 0.1318 | Val loss: 1.8199 | Val Macro F1: 0.1091 | Val Binary F1: 0.7906 | Hackathon: 0.5180 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7200 | Train F1: 0.1629 | Val loss: 1.7733 | Val Macro F1: 0.2362 | Val Binary F1: 0.7906 | Hackathon: 0.5688 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5688)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6726 | Train F1: 0.1707 | Val loss: 1.6657 | Val Macro F1: 0.2397 | Val Binary F1: 0.7906 | Hackathon: 0.5702 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5702)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5990 | Train F1: 0.1999 | Val loss: 1.6441 | Val Macro F1: 0.2479 | Val Binary F1: 0.7906 | Hackathon: 0.5735 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5735)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6125 | Train F1: 0.2170 | Val loss: 1.6517 | Val Macro F1: 0.2537 | Val Binary F1: 0.7906 | Hackathon: 0.5758 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5758)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5973 | Train F1: 0.2724 | Val loss: 1.6459 | Val Macro F1: 0.3580 | Val Binary F1: 0.7906 | Hackathon: 0.6176 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6176)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5390 | Train F1: 0.2432 | Val loss: 1.5941 | Val Macro F1: 0.4410 | Val Binary F1: 0.7906 | Hackathon: 0.6508 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6508)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4806 | Train F1: 0.3122 | Val loss: 1.5444 | Val Macro F1: 0.4671 | Val Binary F1: 0.7906 | Hackathon: 0.6612 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6612)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4913 | Train F1: 0.3406 | Val loss: 1.5817 | Val Macro F1: 0.3460 | Val Binary F1: 0.7906 | Hackathon: 0.6127 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4338 | Train F1: 0.4102 | Val loss: 1.5192 | Val Macro F1: 0.4136 | Val Binary F1: 0.7906 | Hackathon: 0.6398 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4206 | Train F1: 0.4091 | Val loss: 1.5200 | Val Macro F1: 0.3703 | Val Binary F1: 0.7906 | Hackathon: 0.6225 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3800 | Train F1: 0.4196 | Val loss: 1.4702 | Val Macro F1: 0.2934 | Val Binary F1: 0.7906 | Hackathon: 0.5917 | LR: 0.0001\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3702 | Train F1: 0.4264 | Val loss: 1.8939 | Val Macro F1: 0.1376 | Val Binary F1: 0.7906 | Hackathon: 0.5294 | LR: 0.0001\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3167 | Train F1: 0.4168 | Val loss: 1.5697 | Val Macro F1: 0.3590 | Val Binary F1: 0.7906 | Hackathon: 0.6180 | LR: 0.0001\n",
      "No improvement for 6 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2604 | Train F1: 0.4527 | Val loss: 1.4952 | Val Macro F1: 0.5211 | Val Binary F1: 0.7906 | Hackathon: 0.6828 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6828)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2628 | Train F1: 0.4714 | Val loss: 1.6078 | Val Macro F1: 0.2746 | Val Binary F1: 0.7906 | Hackathon: 0.5842 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2398 | Train F1: 0.5107 | Val loss: 1.4698 | Val Macro F1: 0.5496 | Val Binary F1: 0.7906 | Hackathon: 0.6942 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6942)\n",
      "\n",
      "Training complete. Best epoch: 20 (score=0.6942)\n",
      "\n",
      "[exit 0]\n",
      "[07/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.14, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.14_cwp=1.0_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.14_cwp=1.0_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.14_cwp=1.0_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9739 | Train F1: 0.0303 | Val loss: 2.0083 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9047 | Train F1: 0.0580 | Val loss: 1.9853 | Val Macro F1: 0.1425 | Val Binary F1: 0.7906 | Hackathon: 0.5313 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5313)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8529 | Train F1: 0.0977 | Val loss: 1.9049 | Val Macro F1: 0.1136 | Val Binary F1: 0.7906 | Hackathon: 0.5198 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8069 | Train F1: 0.1277 | Val loss: 1.8228 | Val Macro F1: 0.1091 | Val Binary F1: 0.7906 | Hackathon: 0.5180 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7264 | Train F1: 0.1673 | Val loss: 1.7774 | Val Macro F1: 0.2336 | Val Binary F1: 0.7906 | Hackathon: 0.5678 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5678)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6753 | Train F1: 0.1844 | Val loss: 1.6742 | Val Macro F1: 0.2383 | Val Binary F1: 0.7906 | Hackathon: 0.5697 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5697)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6061 | Train F1: 0.1958 | Val loss: 1.6427 | Val Macro F1: 0.2453 | Val Binary F1: 0.7906 | Hackathon: 0.5725 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5725)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6166 | Train F1: 0.2144 | Val loss: 1.6549 | Val Macro F1: 0.2527 | Val Binary F1: 0.7906 | Hackathon: 0.5754 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5754)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5981 | Train F1: 0.2696 | Val loss: 1.6455 | Val Macro F1: 0.3229 | Val Binary F1: 0.7906 | Hackathon: 0.6035 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6035)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5417 | Train F1: 0.2380 | Val loss: 1.6038 | Val Macro F1: 0.4100 | Val Binary F1: 0.7906 | Hackathon: 0.6384 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6384)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4934 | Train F1: 0.2812 | Val loss: 1.5871 | Val Macro F1: 0.2730 | Val Binary F1: 0.7906 | Hackathon: 0.5836 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5108 | Train F1: 0.3270 | Val loss: 1.5944 | Val Macro F1: 0.4233 | Val Binary F1: 0.7906 | Hackathon: 0.6437 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6437)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4363 | Train F1: 0.3877 | Val loss: 1.5588 | Val Macro F1: 0.1455 | Val Binary F1: 0.7906 | Hackathon: 0.5325 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4295 | Train F1: 0.3904 | Val loss: 1.5074 | Val Macro F1: 0.4990 | Val Binary F1: 0.7906 | Hackathon: 0.6740 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6740)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3955 | Train F1: 0.4149 | Val loss: 1.4798 | Val Macro F1: 0.5085 | Val Binary F1: 0.7906 | Hackathon: 0.6778 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6778)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3776 | Train F1: 0.4193 | Val loss: 1.4948 | Val Macro F1: 0.5565 | Val Binary F1: 0.7880 | Hackathon: 0.6954 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6954)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3707 | Train F1: 0.4135 | Val loss: 1.7186 | Val Macro F1: 0.1422 | Val Binary F1: 0.7906 | Hackathon: 0.5312 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3455 | Train F1: 0.4327 | Val loss: 1.5100 | Val Macro F1: 0.5590 | Val Binary F1: 0.8988 | Hackathon: 0.7629 | LR: 0.0001\n",
      "New best model (hackathon_score=0.7629)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3874 | Train F1: 0.4440 | Val loss: 1.5858 | Val Macro F1: 0.4258 | Val Binary F1: 0.7906 | Hackathon: 0.6447 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4006 | Train F1: 0.4522 | Val loss: 1.5613 | Val Macro F1: 0.2605 | Val Binary F1: 0.7906 | Hackathon: 0.5785 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Training complete. Best epoch: 18 (score=0.7629)\n",
      "\n",
      "[exit 0]\n",
      "[08/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 0.95, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=0.95_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.166', '0.499', '0.737', '1.583', '0.759', '1.853', '1.403']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=0.95_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=0.95_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9796 | Train F1: 0.0278 | Val loss: 2.0102 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9130 | Train F1: 0.0407 | Val loss: 1.9829 | Val Macro F1: 0.1442 | Val Binary F1: 0.7906 | Hackathon: 0.5321 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5321)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8613 | Train F1: 0.0948 | Val loss: 1.8997 | Val Macro F1: 0.1119 | Val Binary F1: 0.7906 | Hackathon: 0.5191 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8091 | Train F1: 0.1285 | Val loss: 1.8135 | Val Macro F1: 0.1188 | Val Binary F1: 0.7906 | Hackathon: 0.5219 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7309 | Train F1: 0.1733 | Val loss: 1.7659 | Val Macro F1: 0.2399 | Val Binary F1: 0.7906 | Hackathon: 0.5703 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5703)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6784 | Train F1: 0.1819 | Val loss: 1.6564 | Val Macro F1: 0.2405 | Val Binary F1: 0.7906 | Hackathon: 0.5706 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5706)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6088 | Train F1: 0.2051 | Val loss: 1.6338 | Val Macro F1: 0.2479 | Val Binary F1: 0.7906 | Hackathon: 0.5735 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5735)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6183 | Train F1: 0.2262 | Val loss: 1.6396 | Val Macro F1: 0.2639 | Val Binary F1: 0.7906 | Hackathon: 0.5799 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5799)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6012 | Train F1: 0.2750 | Val loss: 1.6374 | Val Macro F1: 0.3900 | Val Binary F1: 0.7906 | Hackathon: 0.6304 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6304)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5472 | Train F1: 0.2598 | Val loss: 1.5890 | Val Macro F1: 0.5246 | Val Binary F1: 0.7906 | Hackathon: 0.6842 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6842)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4918 | Train F1: 0.3178 | Val loss: 1.5507 | Val Macro F1: 0.4864 | Val Binary F1: 0.7906 | Hackathon: 0.6689 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5082 | Train F1: 0.3443 | Val loss: 1.5733 | Val Macro F1: 0.4302 | Val Binary F1: 0.7906 | Hackathon: 0.6464 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4455 | Train F1: 0.3931 | Val loss: 1.5423 | Val Macro F1: 0.4417 | Val Binary F1: 0.7906 | Hackathon: 0.6510 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4280 | Train F1: 0.4102 | Val loss: 1.5132 | Val Macro F1: 0.5034 | Val Binary F1: 0.7906 | Hackathon: 0.6757 | LR: 0.0001\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3911 | Train F1: 0.4221 | Val loss: 1.4600 | Val Macro F1: 0.4924 | Val Binary F1: 0.7906 | Hackathon: 0.6713 | LR: 0.0001\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3723 | Train F1: 0.4339 | Val loss: 1.6363 | Val Macro F1: 0.3489 | Val Binary F1: 0.7880 | Hackathon: 0.6124 | LR: 0.0001\n",
      "No improvement for 6 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3821 | Train F1: 0.4233 | Val loss: 1.7080 | Val Macro F1: 0.2557 | Val Binary F1: 0.7906 | Hackathon: 0.5767 | LR: 0.0001\n",
      "No improvement for 7 epoch(s)\n",
      "\n",
      "Early stopping at epoch 17\n",
      "\n",
      "Training complete. Best epoch: 10 (score=0.6842)\n",
      "\n",
      "[exit 0]\n",
      "[09/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 1.05, 'balanced_sampler_power': 0.35}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.05_bsp=0.35\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.35, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.135', '0.454', '0.699', '1.628', '0.722', '1.937', '1.425']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.05_bsp=0.35/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.05_bsp=0.35\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9591 | Train F1: 0.0278 | Val loss: 2.0060 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8942 | Train F1: 0.0381 | Val loss: 1.9847 | Val Macro F1: 0.1478 | Val Binary F1: 0.7906 | Hackathon: 0.5335 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5335)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8457 | Train F1: 0.0919 | Val loss: 1.9082 | Val Macro F1: 0.1151 | Val Binary F1: 0.7906 | Hackathon: 0.5204 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7963 | Train F1: 0.1228 | Val loss: 1.8273 | Val Macro F1: 0.1473 | Val Binary F1: 0.7906 | Hackathon: 0.5333 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7190 | Train F1: 0.1610 | Val loss: 1.7848 | Val Macro F1: 0.2309 | Val Binary F1: 0.7906 | Hackathon: 0.5667 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5667)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6715 | Train F1: 0.1728 | Val loss: 1.6812 | Val Macro F1: 0.2383 | Val Binary F1: 0.7906 | Hackathon: 0.5697 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5697)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5990 | Train F1: 0.1810 | Val loss: 1.6517 | Val Macro F1: 0.2453 | Val Binary F1: 0.7906 | Hackathon: 0.5725 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5725)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6101 | Train F1: 0.2120 | Val loss: 1.6640 | Val Macro F1: 0.2527 | Val Binary F1: 0.7906 | Hackathon: 0.5754 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5754)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5926 | Train F1: 0.2566 | Val loss: 1.6574 | Val Macro F1: 0.2728 | Val Binary F1: 0.7906 | Hackathon: 0.5835 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5835)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5351 | Train F1: 0.2290 | Val loss: 1.6159 | Val Macro F1: 0.3182 | Val Binary F1: 0.7906 | Hackathon: 0.6017 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6017)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4872 | Train F1: 0.2819 | Val loss: 1.5589 | Val Macro F1: 0.2732 | Val Binary F1: 0.7906 | Hackathon: 0.5836 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5041 | Train F1: 0.3126 | Val loss: 1.6049 | Val Macro F1: 0.3263 | Val Binary F1: 0.7906 | Hackathon: 0.6049 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6049)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4525 | Train F1: 0.3795 | Val loss: 1.5715 | Val Macro F1: 0.4034 | Val Binary F1: 0.7906 | Hackathon: 0.6357 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6357)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4264 | Train F1: 0.3908 | Val loss: 1.4839 | Val Macro F1: 0.5000 | Val Binary F1: 0.7906 | Hackathon: 0.6743 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6743)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3752 | Train F1: 0.4020 | Val loss: 1.6073 | Val Macro F1: 0.4183 | Val Binary F1: 0.7939 | Hackathon: 0.6436 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3796 | Train F1: 0.3972 | Val loss: 1.4942 | Val Macro F1: 0.5243 | Val Binary F1: 0.7906 | Hackathon: 0.6841 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6841)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3563 | Train F1: 0.4059 | Val loss: 1.5730 | Val Macro F1: 0.3086 | Val Binary F1: 0.7906 | Hackathon: 0.5978 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3118 | Train F1: 0.4105 | Val loss: 1.4725 | Val Macro F1: 0.3260 | Val Binary F1: 0.7906 | Hackathon: 0.6047 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3012 | Train F1: 0.4216 | Val loss: 1.5421 | Val Macro F1: 0.3558 | Val Binary F1: 0.7906 | Hackathon: 0.6167 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2485 | Train F1: 0.4750 | Val loss: 1.4608 | Val Macro F1: 0.5574 | Val Binary F1: 0.7906 | Hackathon: 0.6973 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6973)\n",
      "\n",
      "Training complete. Best epoch: 20 (score=0.6973)\n",
      "\n",
      "[exit 0]\n",
      "[10/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.3}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.3\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.3, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.3/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.3\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9854 | Train F1: 0.0228 | Val loss: 2.0078 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9312 | Train F1: 0.0509 | Val loss: 1.9877 | Val Macro F1: 0.1478 | Val Binary F1: 0.7906 | Hackathon: 0.5335 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5335)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8644 | Train F1: 0.0929 | Val loss: 1.8978 | Val Macro F1: 0.1143 | Val Binary F1: 0.7906 | Hackathon: 0.5201 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8175 | Train F1: 0.1428 | Val loss: 1.8406 | Val Macro F1: 0.1111 | Val Binary F1: 0.7906 | Hackathon: 0.5188 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7256 | Train F1: 0.1908 | Val loss: 1.7821 | Val Macro F1: 0.2350 | Val Binary F1: 0.7906 | Hackathon: 0.5684 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5684)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6905 | Train F1: 0.1784 | Val loss: 1.6962 | Val Macro F1: 0.2369 | Val Binary F1: 0.7906 | Hackathon: 0.5691 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5691)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6288 | Train F1: 0.1800 | Val loss: 1.6643 | Val Macro F1: 0.2453 | Val Binary F1: 0.7906 | Hackathon: 0.5725 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5725)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6081 | Train F1: 0.1999 | Val loss: 1.6520 | Val Macro F1: 0.2461 | Val Binary F1: 0.7906 | Hackathon: 0.5728 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5728)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5777 | Train F1: 0.1931 | Val loss: 1.6226 | Val Macro F1: 0.2505 | Val Binary F1: 0.7906 | Hackathon: 0.5745 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5745)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5618 | Train F1: 0.2219 | Val loss: 1.6218 | Val Macro F1: 0.2552 | Val Binary F1: 0.7906 | Hackathon: 0.5764 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5764)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5316 | Train F1: 0.2977 | Val loss: 1.5270 | Val Macro F1: 0.4370 | Val Binary F1: 0.7906 | Hackathon: 0.6492 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6492)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4563 | Train F1: 0.3820 | Val loss: 1.5422 | Val Macro F1: 0.2328 | Val Binary F1: 0.7906 | Hackathon: 0.5675 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4252 | Train F1: 0.3950 | Val loss: 1.5552 | Val Macro F1: 0.5303 | Val Binary F1: 0.7906 | Hackathon: 0.6865 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6865)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4162 | Train F1: 0.4314 | Val loss: 1.6932 | Val Macro F1: 0.1631 | Val Binary F1: 0.7906 | Hackathon: 0.5396 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3799 | Train F1: 0.4480 | Val loss: 1.8140 | Val Macro F1: 0.0172 | Val Binary F1: 0.7906 | Hackathon: 0.4813 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3809 | Train F1: 0.4367 | Val loss: 1.5872 | Val Macro F1: 0.3876 | Val Binary F1: 0.7906 | Hackathon: 0.6294 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3619 | Train F1: 0.4530 | Val loss: 1.4481 | Val Macro F1: 0.5265 | Val Binary F1: 0.7906 | Hackathon: 0.6850 | LR: 5e-05\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3022 | Train F1: 0.4953 | Val loss: 1.4953 | Val Macro F1: 0.5985 | Val Binary F1: 0.8852 | Hackathon: 0.7705 | LR: 5e-05\n",
      "New best model (hackathon_score=0.7705)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3334 | Train F1: 0.4625 | Val loss: 1.4830 | Val Macro F1: 0.3382 | Val Binary F1: 0.7906 | Hackathon: 0.6097 | LR: 5e-05\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3338 | Train F1: 0.4747 | Val loss: 1.4764 | Val Macro F1: 0.4835 | Val Binary F1: 0.8600 | Hackathon: 0.7094 | LR: 5e-05\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Training complete. Best epoch: 18 (score=0.7705)\n",
      "\n",
      "[exit 0]\n",
      "[11/12] {'lr': 0.0001, 'weight_decay': 7e-05, 'dropout': 0.12, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.4}\n",
      "  → checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.4\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.4, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.4/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.0001_wd=7e-05_do=0.12_cwp=1.0_bsp=0.4\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9376 | Train F1: 0.0288 | Val loss: 2.0061 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 5e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9039 | Train F1: 0.0518 | Val loss: 1.9875 | Val Macro F1: 0.1356 | Val Binary F1: 0.7906 | Hackathon: 0.5286 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5286)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8609 | Train F1: 0.0850 | Val loss: 1.9004 | Val Macro F1: 0.1167 | Val Binary F1: 0.7906 | Hackathon: 0.5211 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7809 | Train F1: 0.1377 | Val loss: 1.8403 | Val Macro F1: 0.1778 | Val Binary F1: 0.7906 | Hackathon: 0.5455 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5455)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7125 | Train F1: 0.1777 | Val loss: 1.7932 | Val Macro F1: 0.2200 | Val Binary F1: 0.7906 | Hackathon: 0.5623 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5623)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6791 | Train F1: 0.1796 | Val loss: 1.6963 | Val Macro F1: 0.2253 | Val Binary F1: 0.7906 | Hackathon: 0.5645 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5645)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6282 | Train F1: 0.2058 | Val loss: 1.6534 | Val Macro F1: 0.2486 | Val Binary F1: 0.7906 | Hackathon: 0.5738 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5738)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6003 | Train F1: 0.2470 | Val loss: 1.6625 | Val Macro F1: 0.2535 | Val Binary F1: 0.7906 | Hackathon: 0.5757 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5757)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5696 | Train F1: 0.2769 | Val loss: 1.6569 | Val Macro F1: 0.2443 | Val Binary F1: 0.7906 | Hackathon: 0.5721 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5198 | Train F1: 0.2299 | Val loss: 1.5957 | Val Macro F1: 0.2687 | Val Binary F1: 0.7906 | Hackathon: 0.5818 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5818)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4716 | Train F1: 0.2961 | Val loss: 1.5913 | Val Macro F1: 0.2314 | Val Binary F1: 0.7906 | Hackathon: 0.5669 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4602 | Train F1: 0.3434 | Val loss: 1.5761 | Val Macro F1: 0.3041 | Val Binary F1: 0.7906 | Hackathon: 0.5960 | LR: 0.0001\n",
      "New best model (hackathon_score=0.5960)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4409 | Train F1: 0.3886 | Val loss: 1.5023 | Val Macro F1: 0.5345 | Val Binary F1: 0.7906 | Hackathon: 0.6882 | LR: 0.0001\n",
      "New best model (hackathon_score=0.6882)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3940 | Train F1: 0.4245 | Val loss: 1.6254 | Val Macro F1: 0.2078 | Val Binary F1: 0.7906 | Hackathon: 0.5575 | LR: 0.0001\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3660 | Train F1: 0.4379 | Val loss: 1.5038 | Val Macro F1: 0.4858 | Val Binary F1: 0.7906 | Hackathon: 0.6687 | LR: 0.0001\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3640 | Train F1: 0.4328 | Val loss: 1.5139 | Val Macro F1: 0.4616 | Val Binary F1: 0.7906 | Hackathon: 0.6590 | LR: 0.0001\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3556 | Train F1: 0.4565 | Val loss: 1.5517 | Val Macro F1: 0.4547 | Val Binary F1: 0.7906 | Hackathon: 0.6563 | LR: 0.0001\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3447 | Train F1: 0.4489 | Val loss: 1.5441 | Val Macro F1: 0.3954 | Val Binary F1: 0.7880 | Hackathon: 0.6309 | LR: 0.0001\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3316 | Train F1: 0.4705 | Val loss: 1.5486 | Val Macro F1: 0.2405 | Val Binary F1: 0.7906 | Hackathon: 0.5705 | LR: 5e-05\n",
      "No improvement for 6 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3337 | Train F1: 0.4625 | Val loss: 1.6197 | Val Macro F1: 0.2665 | Val Binary F1: 0.7906 | Hackathon: 0.5809 | LR: 5e-05\n",
      "No improvement for 7 epoch(s)\n",
      "\n",
      "Early stopping at epoch 20\n",
      "\n",
      "Training complete. Best epoch: 13 (score=0.6882)\n",
      "\n",
      "[exit 0]\n",
      "[12/12] {'lr': 0.00012, 'weight_decay': 0.0001, 'dropout': 0.1, 'class_weight_power': 1.0, 'balanced_sampler_power': 0.4}\n",
      "  → checkpoints/video_research_lr=0.00012_wd=0.0001_do=0.1_cwp=1.0_bsp=0.4\n",
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m video.run_video --config /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/configs/master_config.json\n",
      "Device: cuda\n",
      "\n",
      "Discovering video files in /data1/malto/therness/data/Hackathon...\n",
      "       Scanning good_weld...\n",
      "       Scanning defect-weld...\n",
      "Found 1551 videos\n",
      "  Code 00 (class 0): 731 videos\n",
      "  Code 01 (class 1): 259 videos\n",
      "  Code 02 (class 2): 169 videos\n",
      "  Code 06 (class 3): 79 videos\n",
      "  Code 07 (class 4): 158 videos\n",
      "  Code 08 (class 5): 80 videos\n",
      "  Code 11 (class 6): 75 videos\n",
      "Train: 1268 videos | Val: 283 videos\n",
      "Using pre-extracted frames from data/video_frames\n",
      "Train: 1268 | Val: 283 | num_frames=12 [JPEG]\n",
      "Balanced sampler: enabled (power=0.4, videos/epoch=1268)\n",
      "Model parameters: 190,759\n",
      "Class weights: ['0.150', '0.476', '0.718', '1.606', '0.740', '1.895', '1.414']\n",
      "Config saved to checkpoints/video_research_lr=0.00012_wd=0.0001_do=0.1_cwp=1.0_bsp=0.4/config.json\n",
      "\n",
      "============================================================\n",
      "  TRAINING START — 20 epochs\n",
      "  Checkpoint dir: checkpoints/video_research_lr=0.00012_wd=0.0001_do=0.1_cwp=1.0_bsp=0.4\n",
      "============================================================\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9335 | Train F1: 0.0320 | Val loss: 2.0054 | Val Macro F1: 0.0274 | Val Binary F1: 0.7906 | Hackathon: 0.4853 | LR: 6e-05\n",
      "New best model (hackathon_score=0.4853)\n",
      "\n",
      "Epoch 2/20\n",
      "----------------------------------------\n",
      "Train loss: 1.9083 | Train F1: 0.0460 | Val loss: 1.9863 | Val Macro F1: 0.1327 | Val Binary F1: 0.7906 | Hackathon: 0.5274 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5274)\n",
      "\n",
      "Epoch 3/20\n",
      "----------------------------------------\n",
      "Train loss: 1.8676 | Train F1: 0.0832 | Val loss: 1.9098 | Val Macro F1: 0.1176 | Val Binary F1: 0.7906 | Hackathon: 0.5214 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7921 | Train F1: 0.1210 | Val loss: 1.8576 | Val Macro F1: 0.1691 | Val Binary F1: 0.7906 | Hackathon: 0.5420 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5420)\n",
      "\n",
      "Epoch 5/20\n",
      "----------------------------------------\n",
      "Train loss: 1.7276 | Train F1: 0.1756 | Val loss: 1.8127 | Val Macro F1: 0.2313 | Val Binary F1: 0.7906 | Hackathon: 0.5669 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5669)\n",
      "\n",
      "Epoch 6/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6957 | Train F1: 0.1684 | Val loss: 1.7249 | Val Macro F1: 0.2317 | Val Binary F1: 0.7906 | Hackathon: 0.5671 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5671)\n",
      "\n",
      "Epoch 7/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6489 | Train F1: 0.2137 | Val loss: 1.6882 | Val Macro F1: 0.2533 | Val Binary F1: 0.7906 | Hackathon: 0.5757 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5757)\n",
      "\n",
      "Epoch 8/20\n",
      "----------------------------------------\n",
      "Train loss: 1.6195 | Train F1: 0.2344 | Val loss: 1.7006 | Val Macro F1: 0.2497 | Val Binary F1: 0.7906 | Hackathon: 0.5743 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 9/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5916 | Train F1: 0.2576 | Val loss: 1.7065 | Val Macro F1: 0.2490 | Val Binary F1: 0.7906 | Hackathon: 0.5740 | LR: 0.00012\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 10/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5427 | Train F1: 0.2155 | Val loss: 1.6658 | Val Macro F1: 0.2819 | Val Binary F1: 0.7906 | Hackathon: 0.5871 | LR: 0.00012\n",
      "New best model (hackathon_score=0.5871)\n",
      "\n",
      "Epoch 11/20\n",
      "----------------------------------------\n",
      "Train loss: 1.5082 | Train F1: 0.2835 | Val loss: 1.7157 | Val Macro F1: 0.2617 | Val Binary F1: 0.7906 | Hackathon: 0.5790 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 12/20\n",
      "----------------------------------------\n",
      "Train loss: 1.4548 | Train F1: 0.3860 | Val loss: 1.6150 | Val Macro F1: 0.3601 | Val Binary F1: 0.7906 | Hackathon: 0.6184 | LR: 0.00012\n",
      "New best model (hackathon_score=0.6184)\n",
      "\n",
      "Epoch 13/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3813 | Train F1: 0.4341 | Val loss: 1.5414 | Val Macro F1: 0.4131 | Val Binary F1: 0.7906 | Hackathon: 0.6396 | LR: 0.00012\n",
      "New best model (hackathon_score=0.6396)\n",
      "\n",
      "Epoch 14/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3416 | Train F1: 0.4603 | Val loss: 1.6734 | Val Macro F1: 0.2857 | Val Binary F1: 0.7906 | Hackathon: 0.5886 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 15/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3163 | Train F1: 0.4617 | Val loss: 1.5448 | Val Macro F1: 0.4381 | Val Binary F1: 0.7906 | Hackathon: 0.6496 | LR: 0.00012\n",
      "New best model (hackathon_score=0.6496)\n",
      "\n",
      "Epoch 16/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3103 | Train F1: 0.4655 | Val loss: 1.5415 | Val Macro F1: 0.2361 | Val Binary F1: 0.7906 | Hackathon: 0.5688 | LR: 0.00012\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 17/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3110 | Train F1: 0.4821 | Val loss: 1.5018 | Val Macro F1: 0.3740 | Val Binary F1: 0.7906 | Hackathon: 0.6240 | LR: 0.00012\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 18/20\n",
      "----------------------------------------\n",
      "Train loss: 1.2980 | Train F1: 0.4804 | Val loss: 1.5358 | Val Macro F1: 0.2504 | Val Binary F1: 0.7906 | Hackathon: 0.5745 | LR: 0.00012\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 19/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3203 | Train F1: 0.4458 | Val loss: 1.4942 | Val Macro F1: 0.4255 | Val Binary F1: 0.7906 | Hackathon: 0.6446 | LR: 0.00012\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 20/20\n",
      "----------------------------------------\n",
      "Train loss: 1.3424 | Train F1: 0.4395 | Val loss: 1.6105 | Val Macro F1: 0.4334 | Val Binary F1: 0.7906 | Hackathon: 0.6477 | LR: 0.00012\n",
      "No improvement for 5 epoch(s)\n",
      "\n",
      "Training complete. Best epoch: 15 (score=0.6496)\n",
      "\n",
      "[exit 0]\n",
      "\n",
      "========================================================================================================================\n",
      "VIDEO RESEARCH RESULTS — sorted by macro_f1 (tie-break: hackathon_score)\n",
      "========================================================================================================================\n",
      "  ★ objective=0.6855 score=0.7485 macroF1=0.6855 ep= 20 lr=0.0001 wd=5e-05 do=0.12 cwp=1.0 bsp=0.35\n",
      "    objective=0.5999 score=0.7143 macroF1=0.5999 ep= 19 lr=0.0001 wd=7e-05 do=0.12 cwp=1.0 bsp=0.35\n",
      "    objective=0.5985 score=0.7705 macroF1=0.5985 ep= 18 lr=0.0001 wd=7e-05 do=0.12 cwp=1.0 bsp=0.3\n",
      "    objective=0.5590 score=0.7629 macroF1=0.5590 ep= 18 lr=0.0001 wd=7e-05 do=0.14 cwp=1.0 bsp=0.35\n",
      "    objective=0.5574 score=0.6973 macroF1=0.5574 ep= 20 lr=0.0001 wd=7e-05 do=0.12 cwp=1.05 bsp=0.35\n",
      "    objective=0.5496 score=0.6942 macroF1=0.5496 ep= 20 lr=0.0001 wd=7e-05 do=0.1 cwp=1.0 bsp=0.35\n",
      "    objective=0.5345 score=0.6882 macroF1=0.5345 ep= 13 lr=0.0001 wd=7e-05 do=0.12 cwp=1.0 bsp=0.4\n",
      "    objective=0.5252 score=0.6844 macroF1=0.5252 ep= 11 lr=0.00012 wd=7e-05 do=0.12 cwp=1.0 bsp=0.35\n",
      "    objective=0.5246 score=0.6842 macroF1=0.5246 ep= 10 lr=0.0001 wd=7e-05 do=0.12 cwp=0.95 bsp=0.35\n",
      "    objective=0.4806 score=0.6666 macroF1=0.4806 ep= 17 lr=0.0001 wd=0.0001 do=0.12 cwp=1.0 bsp=0.35\n",
      "    objective=0.4679 score=0.6615 macroF1=0.4679 ep= 13 lr=8e-05 wd=7e-05 do=0.12 cwp=1.0 bsp=0.35\n",
      "    objective=0.4381 score=0.6496 macroF1=0.4381 ep= 15 lr=0.00012 wd=0.0001 do=0.1 cwp=1.0 bsp=0.4\n",
      "========================================================================================================================\n",
      "\n",
      "Best video config:\n",
      "  objective=0.6855 | score=0.7485 | macroF1=0.6855 | lr=0.0001 | wd=5e-05 | dropout=0.12 | class_weight_power=1.0 | balanced_sampler_power=0.35\n",
      "\n",
      "Best params written to master_config.json.\n",
      "Run the next cell to train video with these best params.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Video multiclass research sweep (auto frame sync + F1-aware ranking)\n",
    "import copy\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "\n",
    "RUN_VIDEO_RESEARCH = True\n",
    "FAST_MODE = True\n",
    "MAX_TRIALS = 12\n",
    "RESUME_RESEARCH = False\n",
    "\n",
    "# Research target/selection\n",
    "TARGET_HACKATHON_SCORE = 0.90\n",
    "RESEARCH_OBJECTIVE = 'macro_f1'\n",
    "\n",
    "# Auto-manage frame cache from current config before running trials\n",
    "AUTO_SYNC_FRAME_CACHE = True\n",
    "FRAME_EXTRACT_WORKERS = 16\n",
    "FORCE_REEXTRACT_IF_MISMATCH = True\n",
    "\n",
    "# Optional: apply best params and immediately start a long final training\n",
    "RUN_VIDEO_FINAL_AFTER_RESEARCH = False\n",
    "VIDEO_FINAL_EPOCHS = 140\n",
    "RESET_VIDEO_FINAL_CKPT = True\n",
    "\n",
    "if RUN_VIDEO_RESEARCH:\n",
    "    with open(CONFIG_PATH) as f:\n",
    "        base_cfg = json.load(f)\n",
    "\n",
    "    RESEARCH_EPOCHS = 20 if FAST_MODE else 40\n",
    "    RESEARCH_PATIENCE = 7 if FAST_MODE else 12\n",
    "\n",
    "    def _ensure_frame_cache(cfg):\n",
    "        vw = cfg.get('video_window', {}).get('training', {})\n",
    "        frames_dir = vw.get('frames_dir', 'data/video_frames')\n",
    "        num_frames = int(vw.get('num_frames', 8))\n",
    "        img_size = int(vw.get('img_size', 160))\n",
    "        manifest_path = PROJECT_ROOT / frames_dir / 'manifest.json'\n",
    "\n",
    "        needs_extract = True\n",
    "        reason = 'manifest missing'\n",
    "        if manifest_path.exists():\n",
    "            try:\n",
    "                with open(manifest_path) as f:\n",
    "                    manifest = json.load(f)\n",
    "                m_num_frames = int(manifest.get('num_frames', -1))\n",
    "                m_img_size = int(manifest.get('img_size', -1))\n",
    "                n_entries = len(manifest.get('entries', []))\n",
    "                if m_num_frames == num_frames and m_img_size == img_size and n_entries > 0:\n",
    "                    needs_extract = False\n",
    "                    reason = 'cache already matches config'\n",
    "                else:\n",
    "                    reason = (\n",
    "                        f'cache mismatch (manifest num_frames={m_num_frames}, img_size={m_img_size}, entries={n_entries})'\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                reason = f'manifest unreadable ({e})'\n",
    "\n",
    "        if not needs_extract:\n",
    "            print(f'Frame cache check: OK — {reason}')\n",
    "            return\n",
    "\n",
    "        if not FORCE_REEXTRACT_IF_MISMATCH:\n",
    "            raise RuntimeError(f'Frame cache invalid and FORCE_REEXTRACT_IF_MISMATCH=False: {reason}')\n",
    "\n",
    "        print(f'Frame cache check: rebuilding — {reason}')\n",
    "        cmd = [\n",
    "            PYTHON, '-u', '-m', 'video.extract_frames',\n",
    "            '--data_root', cfg['data_root'],\n",
    "            '--out_dir', str(PROJECT_ROOT / frames_dir),\n",
    "            '--num_frames', str(num_frames),\n",
    "            '--img_size', str(img_size),\n",
    "            '--workers', str(FRAME_EXTRACT_WORKERS),\n",
    "            '--clean',\n",
    "            '--overwrite',\n",
    "        ]\n",
    "        _stream(cmd)\n",
    "\n",
    "        if not manifest_path.exists():\n",
    "            raise FileNotFoundError(f'Manifest not found after extraction: {manifest_path}')\n",
    "\n",
    "        with open(manifest_path) as f:\n",
    "            manifest = json.load(f)\n",
    "        m_num_frames = int(manifest.get('num_frames', -1))\n",
    "        m_img_size = int(manifest.get('img_size', -1))\n",
    "        n_entries = len(manifest.get('entries', []))\n",
    "        if m_num_frames != num_frames or m_img_size != img_size or n_entries <= 0:\n",
    "            raise RuntimeError(\n",
    "                f'Invalid manifest after extraction: num_frames={m_num_frames}, img_size={m_img_size}, entries={n_entries}'\n",
    "            )\n",
    "\n",
    "        print('Frame cache rebuilt and validated.')\n",
    "        print(f'  frames_dir : {(PROJECT_ROOT / frames_dir).resolve()}')\n",
    "        print(f'  entries    : {n_entries}')\n",
    "        print(f'  num_frames : {m_num_frames}')\n",
    "        print(f'  img_size   : {m_img_size}')\n",
    "\n",
    "    if AUTO_SYNC_FRAME_CACHE:\n",
    "        _ensure_frame_cache(base_cfg)\n",
    "    else:\n",
    "        print('AUTO_SYNC_FRAME_CACHE=False — skipping frame cache sync.')\n",
    "\n",
    "    # Focused around latest winner: lr=1e-4, wd=7e-05, dropout=0.12, cwp=1.0, bsp=0.35\n",
    "    candidates = [\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.2e-4, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 8.0e-5, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 5.0e-5, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 1.0e-4, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.10, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.14, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 0.95, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 1.05, 'balanced_sampler_power': 0.35},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.30},\n",
    "        {'lr': 1.0e-4, 'weight_decay': 7.0e-5, 'dropout': 0.12, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.40},\n",
    "        {'lr': 1.2e-4, 'weight_decay': 1.0e-4, 'dropout': 0.10, 'class_weight_power': 1.00, 'balanced_sampler_power': 0.40},\n",
    "    ]\n",
    "\n",
    "    if FAST_MODE:\n",
    "        candidates = candidates[:MAX_TRIALS]\n",
    "\n",
    "    print(f\"Video research: {len(candidates)} trials × {RESEARCH_EPOCHS} epochs\")\n",
    "    print(\n",
    "        f\"FAST_MODE={FAST_MODE} | RESUME_RESEARCH={RESUME_RESEARCH} | \"\n",
    "        f\"OBJECTIVE={RESEARCH_OBJECTIVE} | TARGET_SCORE={TARGET_HACKATHON_SCORE:.2f} | \"\n",
    "        f\"RUN_VIDEO_FINAL_AFTER_RESEARCH={RUN_VIDEO_FINAL_AFTER_RESEARCH}\\n\"\n",
    "    )\n",
    "\n",
    "    def _score_from_ckpt(best_pt, ckpt_dir):\n",
    "        metrics_json = Path(ckpt_dir) / 'best_metrics.json'\n",
    "        if metrics_json.exists():\n",
    "            with open(metrics_json) as f:\n",
    "                m = json.load(f)\n",
    "            score = float(m.get('hackathon_score', m.get('val_f1', -1.0)))\n",
    "            macro_f1 = float(m.get('val_f1', -1.0))\n",
    "            epoch = int(m.get('epoch', -1))\n",
    "            return score, macro_f1, epoch\n",
    "\n",
    "        err = None\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                try:\n",
    "                    ck = torch.load(str(best_pt), map_location='cpu', weights_only=True)\n",
    "                except TypeError:\n",
    "                    ck = torch.load(str(best_pt), map_location='cpu')\n",
    "                score = float(ck.get('hackathon_score', ck.get('val_f1', -1.0)))\n",
    "                macro_f1 = float(ck.get('val_f1', -1.0))\n",
    "                epoch = int(ck.get('epoch', -1))\n",
    "                return score, macro_f1, epoch\n",
    "            except Exception as e:\n",
    "                err = e\n",
    "                time.sleep(0.7)\n",
    "        raise RuntimeError(f'Unable to read checkpoint after retries: {err}')\n",
    "\n",
    "    def _maybe_read_ckpt(best_pt, ckpt_dir):\n",
    "        if not best_pt.exists() and not (Path(ckpt_dir) / 'best_metrics.json').exists():\n",
    "            return None\n",
    "        try:\n",
    "            return _score_from_ckpt(best_pt, ckpt_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"  ↳ Checkpoint/metrics unreadable ({e}); retraining this trial\")\n",
    "            return None\n",
    "\n",
    "    def _objective_value(result_row):\n",
    "        if RESEARCH_OBJECTIVE == 'hackathon_score':\n",
    "            return float(result_row['score'])\n",
    "        return float(result_row['macro_f1'])\n",
    "\n",
    "    def _run_trial(params, idx, total):\n",
    "        tag = (\n",
    "            f\"lr={params['lr']}_wd={params['weight_decay']}\"\n",
    "            f\"_do={params['dropout']}_cwp={params['class_weight_power']}\"\n",
    "            f\"_bsp={params['balanced_sampler_power']}\"\n",
    "        )\n",
    "        ckpt_dir = f\"checkpoints/video_research_{tag}\"\n",
    "        best_pt = Path(ckpt_dir) / 'best_model.pt'\n",
    "\n",
    "        trial_cfg = copy.deepcopy(base_cfg)\n",
    "        tw = trial_cfg['video_window']['training']\n",
    "        tm = trial_cfg['video_window']['model']\n",
    "\n",
    "        tw['epochs'] = RESEARCH_EPOCHS\n",
    "        tw['patience'] = RESEARCH_PATIENCE\n",
    "        tw['checkpoint_dir'] = ckpt_dir\n",
    "        tw['lr'] = params['lr']\n",
    "        tw['weight_decay'] = params['weight_decay']\n",
    "        tw['class_weight_power'] = params['class_weight_power']\n",
    "        tw['use_balanced_sampler'] = True\n",
    "        tw['balanced_sampler_power'] = params['balanced_sampler_power']\n",
    "        tm['dropout'] = params['dropout']\n",
    "\n",
    "        with open(CONFIG_PATH, 'w') as f:\n",
    "            json.dump(trial_cfg, f, indent=2)\n",
    "\n",
    "        print(f\"[{idx:02d}/{total:02d}] {params}\")\n",
    "        print(f\"  → {ckpt_dir}\")\n",
    "\n",
    "        if RESUME_RESEARCH:\n",
    "            prev = _maybe_read_ckpt(best_pt, ckpt_dir)\n",
    "            if prev is not None:\n",
    "                score, macro_f1, epoch = prev\n",
    "                print(\"  ↳ Reusing existing checkpoint\")\n",
    "                return {**params, 'score': score, 'macro_f1': macro_f1, 'epoch': epoch, 'ckpt': ckpt_dir}\n",
    "\n",
    "        try:\n",
    "            _stream([PYTHON, '-u', '-m', 'video.run_video', '--config', str(CONFIG_PATH)])\n",
    "            curr = _maybe_read_ckpt(best_pt, ckpt_dir)\n",
    "            if curr is None:\n",
    "                raise RuntimeError(f\"best_model.pt/best_metrics.json missing in {ckpt_dir}\")\n",
    "            score, macro_f1, epoch = curr\n",
    "            return {**params, 'score': score, 'macro_f1': macro_f1, 'epoch': epoch, 'ckpt': ckpt_dir}\n",
    "        except Exception as e:\n",
    "            print(f\"  FAILED: {e}\")\n",
    "            return {**params, 'score': -1.0, 'macro_f1': -1.0, 'epoch': -1, 'ckpt': ckpt_dir}\n",
    "\n",
    "    results = []\n",
    "    for i, params in enumerate(candidates, start=1):\n",
    "        row = _run_trial(params, i, len(candidates))\n",
    "        results.append(row)\n",
    "        if row['score'] >= TARGET_HACKATHON_SCORE:\n",
    "            print(\n",
    "                f\"\\nTarget reached (hackathon_score={row['score']:.4f} >= {TARGET_HACKATHON_SCORE:.2f}). Stopping sweep early.\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    results.sort(key=lambda r: (_objective_value(r), r['score']), reverse=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(f\"VIDEO RESEARCH RESULTS — sorted by {RESEARCH_OBJECTIVE} (tie-break: hackathon_score)\")\n",
    "    print(\"=\" * 120)\n",
    "    for i, r in enumerate(results):\n",
    "        mark = '★' if i == 0 else ' '\n",
    "        print(\n",
    "            f\"  {mark} objective={_objective_value(r):.4f} score={r['score']:.4f} macroF1={r['macro_f1']:.4f} ep={r['epoch']:3d} \"\n",
    "            f\"lr={r['lr']} wd={r['weight_decay']} do={r['dropout']} \"\n",
    "            f\"cwp={r['class_weight_power']} bsp={r['balanced_sampler_power']}\"\n",
    "        )\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    if not results or results[0]['score'] < 0:\n",
    "        with open(CONFIG_PATH, 'w') as f:\n",
    "            json.dump(base_cfg, f, indent=2)\n",
    "        raise RuntimeError('All video research trials failed.')\n",
    "\n",
    "    best = results[0]\n",
    "    print(\"\\nBest video config:\")\n",
    "    print(\n",
    "        f\"  objective={_objective_value(best):.4f} | score={best['score']:.4f} | macroF1={best['macro_f1']:.4f} | \"\n",
    "        f\"lr={best['lr']} | wd={best['weight_decay']} | dropout={best['dropout']} | \"\n",
    "        f\"class_weight_power={best['class_weight_power']} | balanced_sampler_power={best['balanced_sampler_power']}\"\n",
    "    )\n",
    "\n",
    "    final_cfg = copy.deepcopy(base_cfg)\n",
    "    fw = final_cfg['video_window']['training']\n",
    "    fm = final_cfg['video_window']['model']\n",
    "\n",
    "    fw['lr'] = best['lr']\n",
    "    fw['weight_decay'] = best['weight_decay']\n",
    "    fw['class_weight_power'] = best['class_weight_power']\n",
    "    fw['use_balanced_sampler'] = True\n",
    "    fw['balanced_sampler_power'] = best['balanced_sampler_power']\n",
    "    fm['dropout'] = best['dropout']\n",
    "\n",
    "    if RUN_VIDEO_FINAL_AFTER_RESEARCH:\n",
    "        fw['epochs'] = VIDEO_FINAL_EPOCHS\n",
    "        fw['patience'] = max(20, fw.get('patience', 12))\n",
    "        fw['checkpoint_dir'] = 'checkpoints/video'\n",
    "\n",
    "        final_ckpt_dir = Path(fw['checkpoint_dir'])\n",
    "        if RESET_VIDEO_FINAL_CKPT and final_ckpt_dir.exists():\n",
    "            shutil.rmtree(final_ckpt_dir)\n",
    "            print(f\"Removed checkpoint dir: {final_ckpt_dir.resolve()}\")\n",
    "\n",
    "        with open(CONFIG_PATH, 'w') as f:\n",
    "            json.dump(final_cfg, f, indent=2)\n",
    "\n",
    "        print(f\"\\nStarting final video training for {VIDEO_FINAL_EPOCHS} epochs...\")\n",
    "        _stream([PYTHON, '-u', '-m', 'video.run_video', '--config', str(CONFIG_PATH)])\n",
    "        print('Final video training finished.')\n",
    "    else:\n",
    "        fw['checkpoint_dir'] = 'checkpoints/video'\n",
    "        with open(CONFIG_PATH, 'w') as f:\n",
    "            json.dump(final_cfg, f, indent=2)\n",
    "        print('\\nBest params written to master_config.json.')\n",
    "        print('Run the next cell to train video with these best params.')\n",
    "else:\n",
    "    print('RUN_VIDEO_RESEARCH=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dfa25fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ /home/alolli/miniconda3/envs/therness_env/bin/python -u -m audio.export_deploy_pt --checkpoint checkpoints/audio_multiclass/best_model.pt --output checkpoints/audio_multiclass/deploy_multiclass.pt --device cuda\n",
      "Export mode : multiclass (DeployMulticlassFile)\n",
      "  num_classes    = 7\n",
      "  export_device  = cuda\n",
      "  chunk_samples  = 16000  (1.0s @ 16000 Hz)\n",
      "\n",
      "Saved: /home/alolli/src/malto/hackathon/therness-hackaton-2026-polito/checkpoints/audio_multiclass/deploy_multiclass.pt\n",
      "Methods available on loaded model:\n",
      "  model(waveform)              → file-level prediction\n",
      "  model.predict_window(window) → single-window prediction\n",
      "  model.extract_window_activation(window)    → (128,) embedding\n",
      "  model.extract_file_activations(waveform)   → (T, 128) embeddings\n",
      "  model.extract_file_activation_mean(waveform) → (128,) embedding\n",
      "  model.extract_window_activations(window)   → all stage/head activations\n",
      "  model.extract_file_activation_summary(waveform) → mean stage/head activations\n",
      "\n",
      "[exit 0]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/video/best_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m device = torch.device(EXPORT_DEVICE)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVIDEO_CKPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     39\u001b[39m     ckpt = torch.load(VIDEO_CKPT, map_location=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/therness_env/lib/python3.11/site-packages/torch/serialization.py:1500\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args:\n\u001b[32m   1498\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1501\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1502\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1503\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1504\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1505\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/therness_env/lib/python3.11/site-packages/torch/serialization.py:768\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    767\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/therness_env/lib/python3.11/site-packages/torch/serialization.py:749\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m | os.PathLike[\u001b[38;5;28mstr\u001b[39m], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'checkpoints/video/best_model.pt'"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Export deploy .pt models on GPU (audio + video)\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "RUN_EXPORT_PT = True\n",
    "EXPORT_DEVICE = 'cuda'   # force GPU export\n",
    "AUDIO_DEPLOY_PT = 'checkpoints/audio_multiclass/deploy_multiclass.pt'\n",
    "VIDEO_DEPLOY_PT = 'checkpoints/video/deploy_video.pt'\n",
    "\n",
    "if RUN_EXPORT_PT:\n",
    "    if EXPORT_DEVICE == 'cuda' and not torch.cuda.is_available():\n",
    "        raise RuntimeError('EXPORT_DEVICE=cuda requested, but CUDA is not available.')\n",
    "\n",
    "    with open(CONFIG_PATH) as f:\n",
    "        cfg_live = json.load(f)\n",
    "\n",
    "    # ---- Audio deploy TorchScript (.pt) ----\n",
    "    _stream([\n",
    "        PYTHON, '-u', '-m', 'audio.export_deploy_pt',\n",
    "        '--checkpoint', AUDIO_CKPT,\n",
    "        '--output', AUDIO_DEPLOY_PT,\n",
    "        '--device', EXPORT_DEVICE,\n",
    "    ])\n",
    "\n",
    "    # ---- Video deploy TorchScript (.pt) ----\n",
    "    from models.video_backbone import VideoCNNBackbone\n",
    "    from video.video_processing import WeldVideoModel\n",
    "\n",
    "    num_classes = int(cfg_live.get('num_classes', 7))\n",
    "    dropout = float(cfg_live.get('video_window', {}).get('model', {}).get('dropout', 0.2))\n",
    "\n",
    "    backbone = VideoCNNBackbone(num_classes=num_classes, dropout=dropout)\n",
    "    model = WeldVideoModel(backbone)\n",
    "\n",
    "    device = torch.device(EXPORT_DEVICE)\n",
    "    try:\n",
    "        ckpt = torch.load(VIDEO_CKPT, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        ckpt = torch.load(VIDEO_CKPT, map_location=device)\n",
    "\n",
    "    state = ckpt.get('model_state_dict', ckpt)\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    class DeployVideoPT(torch.nn.Module):\n",
    "        def __init__(self, base_model):\n",
    "            super().__init__()\n",
    "            self.base_model = base_model\n",
    "\n",
    "        def forward(self, frames: torch.Tensor) -> torch.Tensor:\n",
    "            # frames: (B, N, 3, H, W)\n",
    "            return self.base_model(frames)\n",
    "\n",
    "    deploy_video = DeployVideoPT(model).to(device).eval()\n",
    "    example = torch.randn(1, 4, 3, 160, 160, device=device)\n",
    "    scripted_video = torch.jit.trace(deploy_video, example)\n",
    "\n",
    "    out_path = PROJECT_ROOT / VIDEO_DEPLOY_PT\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    scripted_video.save(str(out_path))\n",
    "\n",
    "    print('Export finished.')\n",
    "    print(f'  audio deploy pt: {(PROJECT_ROOT / AUDIO_DEPLOY_PT).resolve()}')\n",
    "    print(f'  video deploy pt: {out_path.resolve()}')\n",
    "    print(f'  export device  : {device}')\n",
    "else:\n",
    "    print('RUN_EXPORT_PT=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Train final video backbone (using best params from previous cell)\n",
    "import shutil\n",
    "\n",
    "RUN_VIDEO_TRAIN = True\n",
    "RESET_VIDEO_CKPT = False\n",
    "\n",
    "with open(CONFIG_PATH) as f:\n",
    "    cfg_live = json.load(f)\n",
    "video_ckpt_dir = Path(cfg_live['video_window']['training'].get('checkpoint_dir', 'checkpoints/video'))\n",
    "\n",
    "if RUN_VIDEO_TRAIN:\n",
    "    if RESET_VIDEO_CKPT and video_ckpt_dir.exists():\n",
    "        shutil.rmtree(video_ckpt_dir)\n",
    "        print(f\"Removed checkpoint dir: {video_ckpt_dir.resolve()}\")\n",
    "\n",
    "    _stream([\n",
    "        PYTHON, '-u', '-m', 'video.run_video',\n",
    "        '--config', str(CONFIG_PATH),\n",
    "    ])\n",
    "else:\n",
    "    print('RUN_VIDEO_TRAIN=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d45c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 — Evaluate video checkpoint\n",
    "RUN_VIDEO_EVAL = True\n",
    "\n",
    "if RUN_VIDEO_EVAL:\n",
    "    _stream([\n",
    "        PYTHON, '-u', '-m', 'video.run_video',\n",
    "        '--config', str(CONFIG_PATH),\n",
    "        '--test_only',\n",
    "        '--checkpoint', VIDEO_CKPT,\n",
    "    ])\n",
    "else:\n",
    "    print('RUN_VIDEO_EVAL=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Train fusion model (true multimodal)\n",
    "RUN_FUSION_TRAIN = True\n",
    "\n",
    "if RUN_FUSION_TRAIN:\n",
    "    _stream([\n",
    "        PYTHON, '-u', '-m', 'fusion.run_fusion',\n",
    "        '--config', str(CONFIG_PATH),\n",
    "        '--audio_checkpoint', AUDIO_CKPT,\n",
    "        '--video_checkpoint', VIDEO_CKPT,\n",
    "    ])\n",
    "else:\n",
    "    print('RUN_FUSION_TRAIN=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975253d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Evaluate fusion checkpoint\n",
    "RUN_FUSION_EVAL = True\n",
    "\n",
    "if RUN_FUSION_EVAL:\n",
    "    _stream([\n",
    "        PYTHON, '-u', '-m', 'fusion.run_fusion',\n",
    "        '--config', str(CONFIG_PATH),\n",
    "        '--audio_checkpoint', AUDIO_CKPT,\n",
    "        '--video_checkpoint', VIDEO_CKPT,\n",
    "        '--test_only',\n",
    "        '--checkpoint', FUSION_CKPT,\n",
    "    ])\n",
    "else:\n",
    "    print('RUN_FUSION_EVAL=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3553da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/video/best_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m video_dropout = \u001b[38;5;28mfloat\u001b[39m(cfg.get(\u001b[33m'\u001b[39m\u001b[33mvideo_window\u001b[39m\u001b[33m'\u001b[39m, {}).get(\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, {}).get(\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0.2\u001b[39m))\n\u001b[32m     53\u001b[39m audio_model = _load_audio_backbone(AUDIO_CKPT, audio_cfg, audio_dropout, device)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m video_model = \u001b[43m_load_video_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVIDEO_CKPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_dropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Build embeddings for the same split\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mExtracting diagnostic embeddings...\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/src/malto/hackathon/therness-hackaton-2026-polito/fusion/run_fusion.py:79\u001b[39m, in \u001b[36m_load_video_backbone\u001b[39m\u001b[34m(checkpoint_path, num_classes, dropout, device)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load trained video backbone for embedding extraction.\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m     81\u001b[39m     ckpt = torch.load(checkpoint_path, map_location=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/therness_env/lib/python3.11/site-packages/torch/serialization.py:1500\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args:\n\u001b[32m   1498\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1501\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1502\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1503\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1504\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1505\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/therness_env/lib/python3.11/site-packages/torch/serialization.py:768\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    767\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/therness_env/lib/python3.11/site-packages/torch/serialization.py:749\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m | os.PathLike[\u001b[38;5;28mstr\u001b[39m], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'checkpoints/video/best_model.pt'"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Fusion diagnostics (full vs audio-only vs video-only)\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fusion.fusion_model import FusionModel, TemporalFusionModel\n",
    "from fusion.run_fusion import (\n",
    "    _load_audio_backbone, _load_video_backbone,\n",
    "    extract_audio_embeddings, extract_video_embeddings,\n",
    "    infer_file_label, _build_video_index, _match_video_files,\n",
    "    load_config,\n",
    ")\n",
    "\n",
    "RUN_FUSION_DIAGNOSTICS = True\n",
    "FUSION_DIAG_CHECKPOINT = FUSION_CKPT\n",
    "\n",
    "if RUN_FUSION_DIAGNOSTICS:\n",
    "    cfg = load_config(str(CONFIG_PATH))\n",
    "    data_root = cfg['data_root']\n",
    "    num_classes = int(cfg.get('num_classes', 7))\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    fusion_cfg = cfg.get('fusion', {})\n",
    "    fusion_model_cfg = fusion_cfg.get('model', {})\n",
    "    fusion_train_cfg = fusion_cfg.get('training', {})\n",
    "    audio_cfg = cfg['audio']['feature_params']\n",
    "    video_train_cfg = cfg.get('video_window', {}).get('training', {})\n",
    "\n",
    "    # Match run_fusion split to evaluate on the same val protocol\n",
    "    all_audio_files = sorted(glob.glob(os.path.join(data_root, '**', '*.flac'), recursive=True))\n",
    "    if not all_audio_files:\n",
    "        raise FileNotFoundError(f'No .flac files in {data_root}')\n",
    "\n",
    "    file_labels = [infer_file_label(f, data_root) for f in all_audio_files]\n",
    "    label_names = sorted(set(file_labels))\n",
    "    label_to_idx = {l: i for i, l in enumerate(label_names)}\n",
    "    labels = [label_to_idx[l] for l in file_labels]\n",
    "\n",
    "    seed = int(fusion_train_cfg.get('seed', 42))\n",
    "    val_split = float(fusion_train_cfg.get('val_split', 0.2))\n",
    "    train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "        all_audio_files, labels, test_size=val_split, random_state=seed, stratify=labels\n",
    "    )\n",
    "\n",
    "    # Load frozen backbones\n",
    "    audio_dropout = float(cfg['audio']['model'].get('dropout', 0.15))\n",
    "    video_dropout = float(cfg.get('video_window', {}).get('model', {}).get('dropout', 0.2))\n",
    "\n",
    "    audio_model = _load_audio_backbone(AUDIO_CKPT, audio_cfg, audio_dropout, device)\n",
    "    video_model = _load_video_backbone(VIDEO_CKPT, num_classes, video_dropout, device)\n",
    "\n",
    "    # Build embeddings for the same split\n",
    "    print('Extracting diagnostic embeddings...')\n",
    "    train_audio_embs = extract_audio_embeddings(audio_model, train_files, audio_cfg, device)\n",
    "    val_audio_embs = extract_audio_embeddings(audio_model, val_files, audio_cfg, device)\n",
    "\n",
    "    video_index = _build_video_index(data_root)\n",
    "    train_video_files, n_train_matched = _match_video_files(train_files, video_index)\n",
    "    val_video_files, n_val_matched = _match_video_files(val_files, video_index)\n",
    "    print(f'Train video match: {n_train_matched}/{len(train_files)}')\n",
    "    print(f'Val video match  : {n_val_matched}/{len(val_files)}')\n",
    "\n",
    "    train_video_embs = extract_video_embeddings(video_model, train_video_files, video_train_cfg, device)\n",
    "    val_video_embs = extract_video_embeddings(video_model, val_video_files, video_train_cfg, device)\n",
    "\n",
    "    # Load trained fusion head\n",
    "    fusion_arch = str(fusion_model_cfg.get('arch', 'mlp')).lower()\n",
    "    if fusion_arch in {'temporal', 'gru', 'sequence'}:\n",
    "        fusion_model = TemporalFusionModel(\n",
    "            audio_dim=int(fusion_model_cfg.get('audio_dim', 128)),\n",
    "            video_dim=int(fusion_model_cfg.get('video_dim', 128)),\n",
    "            hidden_dim=int(fusion_model_cfg.get('hidden_dim', 128)),\n",
    "            num_classes=num_classes,\n",
    "            dropout=float(fusion_model_cfg.get('dropout', 0.2)),\n",
    "            num_layers=int(fusion_model_cfg.get('temporal_layers', 1)),\n",
    "        ).to(device)\n",
    "    else:\n",
    "        fusion_model = FusionModel(\n",
    "            audio_dim=int(fusion_model_cfg.get('audio_dim', 128)),\n",
    "            video_dim=int(fusion_model_cfg.get('video_dim', 128)),\n",
    "            hidden_dim=int(fusion_model_cfg.get('hidden_dim', 128)),\n",
    "            num_classes=num_classes,\n",
    "            dropout=float(fusion_model_cfg.get('dropout', 0.2)),\n",
    "        ).to(device)\n",
    "\n",
    "    try:\n",
    "        ckpt = torch.load(FUSION_DIAG_CHECKPOINT, map_location=device, weights_only=True)\n",
    "    except TypeError:\n",
    "        ckpt = torch.load(FUSION_DIAG_CHECKPOINT, map_location=device)\n",
    "\n",
    "    state = ckpt.get('model_state_dict', ckpt)\n",
    "    fusion_model.load_state_dict(state)\n",
    "    fusion_model.eval()\n",
    "\n",
    "    good_weld_idx = int(ckpt.get('good_weld_idx', label_to_idx.get('good_weld', 0)))\n",
    "    y_true = np.array(val_labels, dtype=int)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _eval_mode(mode: str):\n",
    "        a = val_audio_embs.clone()\n",
    "        v = val_video_embs.clone()\n",
    "        if mode == 'audio_only':\n",
    "            v.zero_()\n",
    "        elif mode == 'video_only':\n",
    "            a.zero_()\n",
    "\n",
    "        logits = fusion_model(a.to(device), v.to(device))\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        macro = f1_score(y_true, preds, average='macro', zero_division=0)\n",
    "        binary_true = np.where(y_true == good_weld_idx, 0, 1)\n",
    "        binary_pred = np.where(preds == good_weld_idx, 0, 1)\n",
    "        binary = f1_score(binary_true, binary_pred, pos_label=1, zero_division=0)\n",
    "        score = 0.6 * binary + 0.4 * macro\n",
    "        return {'mode': mode, 'macro_f1': float(macro), 'binary_f1': float(binary), 'hackathon_score': float(score)}\n",
    "\n",
    "    diag_rows = [_eval_mode('full'), _eval_mode('audio_only'), _eval_mode('video_only')]\n",
    "    diag_rows = sorted(diag_rows, key=lambda r: r['hackathon_score'], reverse=True)\n",
    "\n",
    "    print('\\n' + '=' * 90)\n",
    "    print('FUSION MODALITY DIAGNOSTICS (val split)')\n",
    "    print('=' * 90)\n",
    "    for row in diag_rows:\n",
    "        print(\n",
    "            f\"  mode={row['mode']:10s} | score={row['hackathon_score']:.4f} | \"\n",
    "            f\"macroF1={row['macro_f1']:.4f} | binaryF1={row['binary_f1']:.4f}\"\n",
    "        )\n",
    "    print('=' * 90)\n",
    "\n",
    "    FUSION_DIAG = {\n",
    "        'train_audio_embs': train_audio_embs,\n",
    "        'train_video_embs': train_video_embs,\n",
    "        'train_labels': torch.tensor(train_labels, dtype=torch.long),\n",
    "        'val_audio_embs': val_audio_embs,\n",
    "        'val_video_embs': val_video_embs,\n",
    "        'val_labels': torch.tensor(val_labels, dtype=torch.long),\n",
    "        'good_weld_idx': good_weld_idx,\n",
    "        'num_classes': num_classes,\n",
    "        'rows': diag_rows,\n",
    "    }\n",
    "else:\n",
    "    print('RUN_FUSION_DIAGNOSTICS=False — skipped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdfe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 — Autoencoder latent blend probe (audio+video activations)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "RUN_AE_BLEND_PROBE = True\n",
    "AE_EPOCHS = 35\n",
    "AE_BATCH_SIZE = 128\n",
    "AE_LR = 1e-3\n",
    "AE_RECON_WEIGHT = 0.15\n",
    "AE_LATENT_DIM = 96\n",
    "\n",
    "if RUN_AE_BLEND_PROBE:\n",
    "    if 'FUSION_DIAG' not in globals():\n",
    "        raise RuntimeError('Run Cell 7 first to build FUSION_DIAG embeddings.')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_a = FUSION_DIAG['train_audio_embs'].float()\n",
    "    train_v = FUSION_DIAG['train_video_embs'].float()\n",
    "    train_y = FUSION_DIAG['train_labels'].long()\n",
    "    val_a = FUSION_DIAG['val_audio_embs'].float()\n",
    "    val_v = FUSION_DIAG['val_video_embs'].float()\n",
    "    val_y = FUSION_DIAG['val_labels'].long()\n",
    "    good_weld_idx = int(FUSION_DIAG['good_weld_idx'])\n",
    "    num_classes = int(FUSION_DIAG['num_classes'])\n",
    "\n",
    "    train_x = torch.cat([train_a, train_v], dim=1)  # (N, 256)\n",
    "    val_x = torch.cat([val_a, val_v], dim=1)\n",
    "\n",
    "    class AEFusionProbe(nn.Module):\n",
    "        def __init__(self, in_dim=256, latent_dim=96, num_classes=7, dropout=0.15):\n",
    "            super().__init__()\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(in_dim, 192),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(192, latent_dim),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(latent_dim, 192),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(192, in_dim),\n",
    "            )\n",
    "            self.classifier = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            z = self.encoder(x)\n",
    "            recon = self.decoder(z)\n",
    "            logits = self.classifier(z)\n",
    "            return logits, recon\n",
    "\n",
    "    model = AEFusionProbe(\n",
    "        in_dim=train_x.shape[1],\n",
    "        latent_dim=AE_LATENT_DIM,\n",
    "        num_classes=num_classes,\n",
    "        dropout=0.15,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=AE_LR, weight_decay=1e-4)\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    best = {'score': -1.0, 'macro_f1': -1.0, 'binary_f1': -1.0, 'epoch': -1}\n",
    "\n",
    "    n = train_x.shape[0]\n",
    "    for epoch in range(1, AE_EPOCHS + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(n)\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for i in range(0, n, AE_BATCH_SIZE):\n",
    "            idx = perm[i:i + AE_BATCH_SIZE]\n",
    "            xb = train_x[idx].to(device)\n",
    "            yb = train_y[idx].to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits, recon = model(xb)\n",
    "            loss = ce_loss(logits, yb) + AE_RECON_WEIGHT * mse_loss(recon, xb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += float(loss.item()) * xb.size(0)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(val_x.to(device))\n",
    "            preds = logits.argmax(dim=1).cpu()\n",
    "\n",
    "        y_true = val_y.numpy()\n",
    "        y_pred = preds.numpy()\n",
    "\n",
    "        macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "        bin_true = [0 if y == good_weld_idx else 1 for y in y_true]\n",
    "        bin_pred = [0 if p == good_weld_idx else 1 for p in y_pred]\n",
    "        binary = f1_score(bin_true, bin_pred, pos_label=1, zero_division=0)\n",
    "        score = 0.6 * binary + 0.4 * macro\n",
    "\n",
    "        if score > best['score']:\n",
    "            best = {\n",
    "                'score': float(score),\n",
    "                'macro_f1': float(macro),\n",
    "                'binary_f1': float(binary),\n",
    "                'epoch': int(epoch),\n",
    "            }\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0 or epoch == AE_EPOCHS:\n",
    "            avg_loss = epoch_loss / max(n, 1)\n",
    "            print(\n",
    "                f\"epoch={epoch:02d} loss={avg_loss:.4f} \"\n",
    "                f\"val_score={score:.4f} macroF1={macro:.4f} binaryF1={binary:.4f}\"\n",
    "            )\n",
    "\n",
    "    print('\\n' + '=' * 90)\n",
    "    print('AE LATENT BLEND PROBE — BEST VAL RESULT')\n",
    "    print('=' * 90)\n",
    "    print(\n",
    "        f\"  score={best['score']:.4f} | macroF1={best['macro_f1']:.4f} | \"\n",
    "        f\"binaryF1={best['binary_f1']:.4f} | epoch={best['epoch']}\"\n",
    "    )\n",
    "    print('=' * 90)\n",
    "\n",
    "    FUSION_AE_PROBE_BEST = best\n",
    "else:\n",
    "    print('RUN_AE_BLEND_PROBE=False — skipped.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "therness_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
